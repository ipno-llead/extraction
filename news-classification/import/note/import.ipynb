{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "from numpy import nan as nan\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id tracking\n",
    "| df | article_id | matchedsentence_id | officer_id |\n",
    "|:--- | ---: | ---: | :---:|\n",
    "| text_df | text_df.id|X|X|\n",
    "| sen_df  | sen_df.article_id|sen_df.id|X|\n",
    "| true_df | X |true_df.matchedsentence_id|true_df.id|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support methods for notebook version\n",
    "def get_unique_report(df):\n",
    "    cols = list(df.columns)\n",
    "    print('             distinct value count by col')\n",
    "    print('=======================================================')\n",
    "    for col in cols:\n",
    "        pretty_print(col, len(df[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support methods\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--included\", default='input/news_articles_matchedsentence.csv.gz')\n",
    "    parser.add_argument(\"--true\", default='input/news_articles_matchedsentence_officers.csv.gz')\n",
    "    parser.add_argument(\"--text\", default='input/news_articles_newsarticle.csv.gz')\n",
    "    parser.add_argument(\"--output\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def get_logging(logname):\n",
    "        logging.basicConfig(level=logging.DEBUG,\n",
    "                            format='%(asctime)s %(levelname)s %(message)s',\n",
    "                            handlers=[logging.FileHandler(logname),\n",
    "                            logging.StreamHandler()])\n",
    "\n",
    "\n",
    "def open_gz(f):\n",
    "    return pd.read_csv(f, compression='gzip')\n",
    "\n",
    "\n",
    "def pretty_print(label, val, newline=False):\n",
    "    print('{:50}{}'.format(label, val))\n",
    "    if newline:\n",
    "        print()\n",
    "\n",
    "\n",
    "def check_asserts(text_df, sen_df, true_df):\n",
    "    # asserts first\n",
    "    assert text_df.shape == (29707, 12)\n",
    "    assert sen_df.shape == (10470, 7)\n",
    "    assert true_df.shape == (735, 3)\n",
    "    assert all(text_df.columns == ['created_at', 'link', 'guid', 'source_id', \\\n",
    "                                   'updated_at', 'content', 'published_date', 'id', \\\n",
    "                                   'title', 'is_processed', 'author', 'url'])\n",
    "    assert all(sen_df.columns == ['id', 'created_at', 'updated_at', 'article_id', \n",
    "                                   'extracted_keywords', 'text', 'title'])\n",
    "    assert all(true_df.columns == ['id', 'matchedsentence_id', 'officer_id'])\n",
    "    most = set(text_df.id.unique())\n",
    "    mid = set(sen_df.id.unique())\n",
    "    least = set(true_df.id.unique())\n",
    "    assert len(least) < len(mid) < len(most)\n",
    "    assert len(most.intersection(mid)) == 9891\n",
    "    assert all(true_df.id == true_df.officer_id)   # what does it mean that this is true? will it always?\n",
    "    pairs = set()\n",
    "    for tup in true_df.itertuples():\n",
    "        pairs.add((tup.id, tup.matchedsentence_id))\n",
    "    assert len(pairs) == true_df.shape[0]\n",
    "    articles = text_df.id.unique()\n",
    "    matched = sen_df.article_id.unique()\n",
    "    assert len(matched) < len(articles)\n",
    "    assert len(articles) == 29707\n",
    "    assert len(matched) == 4323\n",
    "    for match in matched:\n",
    "        assert match in articles\n",
    "    matched_sen = sen_df.id.unique()\n",
    "    true_match_sen = true_df.matchedsentence_id.unique()\n",
    "    true_match_off = true_df.id.unique()\n",
    "    assert len(true_match_sen) < len(matched_sen)\n",
    "    assert len(matched_sen) == 10470\n",
    "    assert len(true_match_sen) == 479\n",
    "    for match in true_match_sen:\n",
    "        assert match in matched_sen\n",
    "    #reporting/logging second\n",
    "    print('                overview of input')\n",
    "    print('=======================================================')\n",
    "    pretty_print('raw article data:', text_df.shape)\n",
    "    pretty_print('matched kw data:', sen_df.shape)\n",
    "    pretty_print('relevant sentence/officer data:', true_df.shape)\n",
    "    pretty_print('unique articles:', len(articles))\n",
    "    pretty_print('unique articles w/ kw match:', len(matched))\n",
    "    pretty_print('unique matched sentences:', len(matched_sen))\n",
    "    pretty_print('unique matched sentences relevant:', len(true_match_sen))\n",
    "    pretty_print('unique matched officers relevant:', len(true_match_off))\n",
    "\n",
    "\n",
    "def prep_dfs(text_df, sen_df, true_df):\n",
    "    less_text = text_df.loc[:, ['id', 'source_id', 'author', 'content']]\n",
    "    temp = less_text\n",
    "    less_text = temp.rename(columns={'id':'article_id'})\n",
    "    less_sen = sen_df.loc[:, ['id', 'article_id', 'extracted_keywords']]\n",
    "    temp = less_sen\n",
    "    less_sen = temp.rename(columns={'id':'matchedsentence_id'})\n",
    "    less_sen['kw_match'] = [1 for val in range(less_sen.shape[0])]\n",
    "    less_true = true_df.loc[:, ['officer_id', 'matchedsentence_id']]\n",
    "    less_true['relevant'] = [1 for val in range(less_true.shape[0])]\n",
    "    return less_text, less_sen, less_true\n",
    "\n",
    "\n",
    "def merge_dfs(less_text, less_sen, less_true):\n",
    "    less_text = less_text.set_index('article_id')\n",
    "    less_sen = less_sen.set_index('article_id')\n",
    "    out = less_text.join(less_sen, on='article_id', how='outer').reset_index().set_index('matchedsentence_id')\n",
    "    temp = less_true\n",
    "    less_true = temp.set_index('matchedsentence_id')\n",
    "    out = out.join(less_true, on='matchedsentence_id', how='outer')\n",
    "    out = out.reset_index()\n",
    "    out.kw_match.fillna(value=0, axis=0, inplace=True)\n",
    "    out.relevant.fillna(value=0, axis=0, inplace=True)\n",
    "    temp = out\n",
    "    out['kw_match'] = temp.kw_match.astype(int)\n",
    "    out['relevant'] = temp.relevant.astype(int)\n",
    "    return out\n",
    "\n",
    "\n",
    "def invert_bool_list(aList):\n",
    "    mask = [1 if val == 0 else 0 for val in aList]\n",
    "    return pd.array(mask, dtype=\"boolean\")\n",
    "\n",
    "\n",
    "# Per TS, starting train/test size should be 500/100\n",
    "# ASSUMPTION: A 50/50 POS/NEG balance for model is reasonable starting point\n",
    "# This method builds the POSITIVE cases: keyword matched AND article relevant (per Rajiv)\n",
    "def prep_pos_train_test(merged, train_n=250, test_n=50):\n",
    "    id_mask = (merged.officer_id.notnull())\n",
    "    possible = merged.loc[id_mask].officer_id.unique().tolist()\n",
    "    train_list, test_list = train_test_split(possible, test_size=test_n, train_size=train_n, shuffle=True)\n",
    "    assert set(train_list).isdisjoint(set(test_list))\n",
    "    return train_list, test_list\n",
    "\n",
    "\n",
    "# This method builds the NEGATIVE cases: keyword matched but not relevant\n",
    "def prep_neg_train_test(rem_df, train_n=250, test_n=50):\n",
    "    id_mask = (rem_df.kw_match == 1) & (rem_df.officer_id.isnull())\n",
    "    possible = rem_df.loc[id_mask].matchedsentence_id.unique().tolist()\n",
    "    train_list, test_list = train_test_split(possible, test_size=test_n, train_size=train_n, shuffle=True)\n",
    "    assert set(train_list).isdisjoint(set(test_list))\n",
    "    return train_list, test_list\n",
    "\n",
    "\n",
    "def get_train_test_dfs(merged):\n",
    "    pos_train_idx, pos_test_idx = prep_pos_train_test(merged)\n",
    "    pos_train_df = merged.loc[merged.officer_id.isin(pos_train_idx)]\n",
    "    pos_test_df = merged.loc[merged.officer_id.isin(pos_test_idx)]\n",
    "    # combine train and test indices\n",
    "    # use combined indices as mask, then invert the mask so T->F, F->T\n",
    "    # use inverted mask to get remainder data that is not in either train or test sets\n",
    "    pos_combined = pos_train_idx + pos_test_idx\n",
    "    assert invert_bool_list([1,1,1,0,0,0]) == [0,0,0,1,1,1]\n",
    "    mask_to_inv = (merged.officer_id.isin(pos_combined))\n",
    "    pos_inv_mask = invert_bool_list(mask_to_inv)\n",
    "    initial_rem_df = merged.loc[pos_inv_mask]\n",
    "    assert len(pos_train_df.officer_id.unique()) == 250\n",
    "    assert len(pos_test_df.officer_id.unique()) == 50\n",
    "    # use remainder data to pad train and test sets with negative cases\n",
    "    neg_train_idx, neg_test_idx = prep_neg_train_test(initial_rem_df)\n",
    "    neg_train_df = initial_rem_df.loc[initial_rem_df.matchedsentence_id.isin(neg_train_idx)]\n",
    "    neg_test_df = initial_rem_df.loc[initial_rem_df.matchedsentence_id.isin(neg_test_idx)]\n",
    "    neg_train_idx, neg_test_idx = prep_neg_train_test(initial_rem_df)\n",
    "    neg_combined = neg_train_idx + neg_test_idx\n",
    "    mask_to_inv = (merged.matchedsentence_id.isin(neg_combined) | merged.officer_id.isin(pos_combined))\n",
    "    inv_mask = invert_bool_list(mask_to_inv)\n",
    "    final_rem_df = merged.loc[inv_mask]\n",
    "    train_df = pd.concat([pos_train_df, neg_train_df])\n",
    "    test_df = pd.concat([pos_test_df, neg_test_df])\n",
    "    return train_df, test_df, final_rem_df\n",
    "\n",
    "\n",
    "def remake_merged(train_df, test_df, rem_df):\n",
    "    train_test_df = pd.concat([train_df, test_df])\n",
    "    train_test_df['train_test'] = [1 for val in range(train_test_df.shape[0])]\n",
    "    temp = rem_df.copy()\n",
    "    temp['train_test'] = [0 for val in range(temp.shape[0])]\n",
    "    return pd.concat([train_test_df, temp])\n",
    "\n",
    "\n",
    "def make_source_reports(train_df, test_df, rem_df):\n",
    "    train_vc = train_df.source_id.value_counts().to_dict()\n",
    "    test_vc = test_df.source_id.value_counts().to_dict()\n",
    "    rem_vc = rem_df.source_id.value_counts().to_dict()\n",
    "    sources = set(list(train_vc.keys()) + list(test_vc.keys()) + list(rem_vc.keys()))\n",
    "    out_data = {source:{} for source in sources}\n",
    "    for source in sources:\n",
    "        if source in train_vc:\n",
    "            out_data[source]['train_df'] = train_vc[source]\n",
    "        else:\n",
    "            out_data[source]['train_df'] = nan\n",
    "        if source in test_vc:\n",
    "            out_data[source]['test_df'] = test_vc[source]\n",
    "        else:\n",
    "            out_data[source]['test_df'] = nan\n",
    "        if source in rem_vc:\n",
    "            out_data[source]['rem_df'] = rem_vc[source]\n",
    "        else:\n",
    "            out_data[source]['rem_df'] = nan\n",
    "    return pd.DataFrame.from_dict(out_data).T.reset_index().rename(columns={'index':'source_id'})\n",
    "\n",
    "\n",
    "def make_author_reports(train_df, test_df, rem_df):\n",
    "    train_vc = train_df.author.value_counts().to_dict()\n",
    "    test_vc = test_df.author.value_counts().to_dict()\n",
    "    rem_vc = rem_df.author.value_counts().to_dict()\n",
    "    authors = set(list(train_vc.keys()) + list(test_vc.keys()) + list(rem_vc.keys()))\n",
    "    out_data = {author:{} for author in authors}\n",
    "    for author in authors:\n",
    "        if author in train_vc:\n",
    "            out_data[author]['train_df'] = train_vc[author]\n",
    "        else:\n",
    "            out_data[author]['train_df'] = nan\n",
    "        if author in test_vc:\n",
    "            out_data[author]['test_df'] = test_vc[author]\n",
    "        else:\n",
    "            out_data[author]['test_df'] = nan\n",
    "        if author in rem_vc:\n",
    "            out_data[author]['rem_df'] = rem_vc[author]\n",
    "        else:\n",
    "            out_data[author]['rem_df'] = nan\n",
    "    return pd.DataFrame.from_dict(out_data).T.reset_index().rename(columns={'index':'author'})\n",
    "\n",
    "\n",
    "def make_kw_reports(train_df, test_df, rem_df):\n",
    "    train_vc = train_df.extracted_keywords.value_counts().to_dict()\n",
    "    test_vc = test_df.extracted_keywords.value_counts().to_dict()\n",
    "    rem_vc = rem_df.extracted_keywords.value_counts().to_dict()\n",
    "    kws = set(list(train_vc.keys()) + list(test_vc.keys()) + list(rem_vc.keys()))\n",
    "    out_data = {kw:{} for kw in kws}\n",
    "    for kw in kws:\n",
    "        if kw in train_vc:\n",
    "            out_data[kw]['train_df'] = train_vc[kw]\n",
    "        else:\n",
    "            out_data[kw]['train_df'] = nan\n",
    "        if kw in test_vc:\n",
    "            out_data[kw]['test_df'] = test_vc[kw]\n",
    "        else:\n",
    "            out_data[kw]['test_df'] = nan\n",
    "        if kw in rem_vc:\n",
    "            out_data[kw]['rem_df'] = rem_vc[kw]\n",
    "        else:\n",
    "            out_data[kw]['rem_df'] = nan\n",
    "    return pd.DataFrame.from_dict(out_data).T.reset_index().rename(columns={'index':'extracted_keywords'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO OUTPUT:\n",
    "# 1. article_id (given in data)\n",
    "# 2. article text (given in data)\n",
    "# 3. relevant (if article in true_df)\n",
    "# 4. test (if article is reserved for testing model)     Per TS: 500 train, 100 test for initial train\n",
    "# (may add cols like author or title)\n",
    "\n",
    "# CONSIDERING\n",
    "#train_df['train'] = [1 for val in range(train_df.shape[0])]\n",
    "#test_df['test'] = [1 for val in range(test_df.shape[0])]\n",
    "#pd.concat([train_df, test_df, rem_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                overview of input\n",
      "=======================================================\n",
      "raw article data:                                 (29707, 12)\n",
      "matched kw data:                                  (10470, 7)\n",
      "relevant sentence/officer data:                   (735, 3)\n",
      "unique articles:                                  29707\n",
      "unique articles w/ kw match:                      4323\n",
      "unique matched sentences:                         10470\n",
      "unique matched sentences relevant:                479\n",
      "unique matched officers relevant:                 355\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('mode.chained_assignment', 'raise')\n",
    "# __main__\n",
    "#\n",
    "# newsarticle: initial dataset\n",
    "#    - has all the data related to the article as it was pulled into feed\n",
    "# matchedsentence: initial keyword filter\n",
    "#    - has all the data related to every article with at least one sentence matching a keyword\n",
    "# matchedsentence_officers: manual filter (Rajiv)\n",
    "#    - has select columns linking identified officer badges and articles confirmed relevant by Rajiv\n",
    "# NOTE: If an article is not in the manual filter set, it is not relevant\n",
    "news_text = '../input/news_articles_newsarticle.csv.gz'\n",
    "news_included = '../input/news_articles_matchedsentence.csv.gz'\n",
    "news_true = '../input/news_articles_matchedsentence_officers.csv.gz'\n",
    "\n",
    "text_df = open_gz(news_text)\n",
    "sen_df = open_gz(news_included)\n",
    "true_df = open_gz(news_true)\n",
    "check_asserts(text_df, sen_df, true_df)\n",
    "\n",
    "less_text, less_sen, less_true = prep_dfs(text_df, sen_df, true_df)\n",
    "merged = merge_dfs(less_text, less_sen, less_true)\n",
    "train_df, test_df, rem_df = get_train_test_dfs(merged)\n",
    "src_report = make_source_reports(train_df, test_df, rem_df)\n",
    "author_report = make_author_reports(train_df, test_df, rem_df)\n",
    "kw_report = make_kw_reports(train_df, test_df, rem_df)\n",
    "news = remake_merged(train_df, test_df, rem_df)\n",
    "less_train = train_df.loc[:, ['article_id', 'content', 'relevant']]\n",
    "less_test = test_df.loc[:, ['article_id', 'content', 'relevant']]\n",
    "\n",
    "# save outputs\n",
    "news.to_parquet('../output/news.parquet')\n",
    "less_train.to_parquet('../output/train.parquet')\n",
    "less_test.to_parquet('../output/test.parquet')\n",
    "src_report.to_parquet('../output/source_report.parquet')\n",
    "author_report.to_parquet('../output/author_report.parquet')\n",
    "kw_report.to_parquet('../output/keyword_report.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchedsentence_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>extracted_keywords</th>\n",
       "      <th>kw_match</th>\n",
       "      <th>officer_id</th>\n",
       "      <th>relevant</th>\n",
       "      <th>train_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25630</th>\n",
       "      <td>13559.0</td>\n",
       "      <td>30695</td>\n",
       "      <td>32</td>\n",
       "      <td>Kendrick Dante, Shreveport Times</td>\n",
       "      <td>The April 11 death of a Shreveport inmatejustd...</td>\n",
       "      <td>[\"officer\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>95596.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25680</th>\n",
       "      <td>13632.0</td>\n",
       "      <td>30616</td>\n",
       "      <td>17</td>\n",
       "      <td>Piper Hutchinson</td>\n",
       "      <td>\\n(LSU Manship School News Service) – Third Di...</td>\n",
       "      <td>[\"Police\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>138540.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25682</th>\n",
       "      <td>13632.0</td>\n",
       "      <td>30616</td>\n",
       "      <td>17</td>\n",
       "      <td>Piper Hutchinson</td>\n",
       "      <td>\\n(LSU Manship School News Service) – Third Di...</td>\n",
       "      <td>[\"Police\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>115121.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25844</th>\n",
       "      <td>13340.0</td>\n",
       "      <td>30133</td>\n",
       "      <td>30</td>\n",
       "      <td>WBRZ Staff</td>\n",
       "      <td>LAPLACE - A sheriff&amp;#x27;s deputy shot and wou...</td>\n",
       "      <td>[\"Police\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>138401.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25933</th>\n",
       "      <td>13215.0</td>\n",
       "      <td>29874</td>\n",
       "      <td>2</td>\n",
       "      <td>James Finn</td>\n",
       "      <td>A Baton Rouge policeman at the center of an on...</td>\n",
       "      <td>[\"officer\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>95596.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36105</th>\n",
       "      <td>9.0</td>\n",
       "      <td>373</td>\n",
       "      <td>1</td>\n",
       "      <td>Marta Jewson</td>\n",
       "      <td>At a press conference Wednesday, NOLA Public S...</td>\n",
       "      <td>[\"Officer\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36106</th>\n",
       "      <td>3.0</td>\n",
       "      <td>366</td>\n",
       "      <td>1</td>\n",
       "      <td>Carly Berlin</td>\n",
       "      <td>UPDATE: After this story was published, FEMA e...</td>\n",
       "      <td>[\"Officer\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36107</th>\n",
       "      <td>2.0</td>\n",
       "      <td>365</td>\n",
       "      <td>1</td>\n",
       "      <td>Marta Jewson</td>\n",
       "      <td>Outside Frederick Douglass High School Thursda...</td>\n",
       "      <td>[\"Officer\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>362</td>\n",
       "      <td>1</td>\n",
       "      <td>Marta Jewson</td>\n",
       "      <td>About 250,000 Louisiana students remain out of...</td>\n",
       "      <td>[\"Officer\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36109</th>\n",
       "      <td>6.0</td>\n",
       "      <td>356</td>\n",
       "      <td>1</td>\n",
       "      <td>Michael Isaac Stein</td>\n",
       "      <td>One week after Hurricane Ida made landfall in ...</td>\n",
       "      <td>[\"Police\"]</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36110 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       matchedsentence_id  article_id  source_id  \\\n",
       "25630             13559.0       30695         32   \n",
       "25680             13632.0       30616         17   \n",
       "25682             13632.0       30616         17   \n",
       "25844             13340.0       30133         30   \n",
       "25933             13215.0       29874          2   \n",
       "...                   ...         ...        ...   \n",
       "36105                 9.0         373          1   \n",
       "36106                 3.0         366          1   \n",
       "36107                 2.0         365          1   \n",
       "36108                 1.0         362          1   \n",
       "36109                 6.0         356          1   \n",
       "\n",
       "                                 author  \\\n",
       "25630  Kendrick Dante, Shreveport Times   \n",
       "25680                 Piper Hutchinson    \n",
       "25682                 Piper Hutchinson    \n",
       "25844                        WBRZ Staff   \n",
       "25933                        James Finn   \n",
       "...                                 ...   \n",
       "36105                      Marta Jewson   \n",
       "36106                      Carly Berlin   \n",
       "36107                      Marta Jewson   \n",
       "36108                      Marta Jewson   \n",
       "36109               Michael Isaac Stein   \n",
       "\n",
       "                                                 content extracted_keywords  \\\n",
       "25630  The April 11 death of a Shreveport inmatejustd...        [\"officer\"]   \n",
       "25680  \\n(LSU Manship School News Service) – Third Di...         [\"Police\"]   \n",
       "25682  \\n(LSU Manship School News Service) – Third Di...         [\"Police\"]   \n",
       "25844  LAPLACE - A sheriff&#x27;s deputy shot and wou...         [\"Police\"]   \n",
       "25933  A Baton Rouge policeman at the center of an on...        [\"officer\"]   \n",
       "...                                                  ...                ...   \n",
       "36105  At a press conference Wednesday, NOLA Public S...        [\"Officer\"]   \n",
       "36106  UPDATE: After this story was published, FEMA e...        [\"Officer\"]   \n",
       "36107  Outside Frederick Douglass High School Thursda...        [\"Officer\"]   \n",
       "36108  About 250,000 Louisiana students remain out of...        [\"Officer\"]   \n",
       "36109  One week after Hurricane Ida made landfall in ...         [\"Police\"]   \n",
       "\n",
       "       kw_match  officer_id  relevant  train_test  \n",
       "25630         1     95596.0         1           1  \n",
       "25680         1    138540.0         1           1  \n",
       "25682         1    115121.0         1           1  \n",
       "25844         1    138401.0         1           1  \n",
       "25933         1     95596.0         1           1  \n",
       "...         ...         ...       ...         ...  \n",
       "36105         1         NaN         0           0  \n",
       "36106         1         NaN         0           0  \n",
       "36107         1         NaN         0           0  \n",
       "36108         1         NaN         0           0  \n",
       "36109         1         NaN         0           0  \n",
       "\n",
       "[36110 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25679</th>\n",
       "      <td>30616</td>\n",
       "      <td>\\n(LSU Manship School News Service) – Third Di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25680</th>\n",
       "      <td>30616</td>\n",
       "      <td>\\n(LSU Manship School News Service) – Third Di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25681</th>\n",
       "      <td>30616</td>\n",
       "      <td>\\n(LSU Manship School News Service) – Third Di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25844</th>\n",
       "      <td>30133</td>\n",
       "      <td>LAPLACE - A sheriff&amp;#x27;s deputy shot and wou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25935</th>\n",
       "      <td>29874</td>\n",
       "      <td>A Baton Rouge policeman at the center of an on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35922</th>\n",
       "      <td>921</td>\n",
       "      <td>A drunk driver hit a pedestrian in Ascension P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35952</th>\n",
       "      <td>780</td>\n",
       "      <td>Opelousas Police are investigating a shooting ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36015</th>\n",
       "      <td>626</td>\n",
       "      <td>Addy Melancon, the last living veteran of the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36033</th>\n",
       "      <td>459</td>\n",
       "      <td>St. Tammany Parish voters will finally get to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36081</th>\n",
       "      <td>405</td>\n",
       "      <td>A Louisiana State Police trooper who initiated...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>790 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id                                            content  relevant\n",
       "25679       30616  \\n(LSU Manship School News Service) – Third Di...         1\n",
       "25680       30616  \\n(LSU Manship School News Service) – Third Di...         1\n",
       "25681       30616  \\n(LSU Manship School News Service) – Third Di...         1\n",
       "25844       30133  LAPLACE - A sheriff&#x27;s deputy shot and wou...         1\n",
       "25935       29874  A Baton Rouge policeman at the center of an on...         1\n",
       "...           ...                                                ...       ...\n",
       "35922         921  A drunk driver hit a pedestrian in Ascension P...         0\n",
       "35952         780  Opelousas Police are investigating a shooting ...         0\n",
       "36015         626  Addy Melancon, the last living veteran of the ...         0\n",
       "36033         459  St. Tammany Parish voters will finally get to ...         0\n",
       "36081         405  A Louisiana State Police trooper who initiated...         0\n",
       "\n",
       "[790 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25630</th>\n",
       "      <td>30695</td>\n",
       "      <td>The April 11 death of a Shreveport inmatejustd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25933</th>\n",
       "      <td>29874</td>\n",
       "      <td>A Baton Rouge policeman at the center of an on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25976</th>\n",
       "      <td>29704</td>\n",
       "      <td>A Lafayette man filed a lawsuit in federal cou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25979</th>\n",
       "      <td>29704</td>\n",
       "      <td>A Lafayette man filed a lawsuit in federal cou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25980</th>\n",
       "      <td>29704</td>\n",
       "      <td>A Lafayette man filed a lawsuit in federal cou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35415</th>\n",
       "      <td>1880</td>\n",
       "      <td>The LSU Tigers are covering some familiar grou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35554</th>\n",
       "      <td>1614</td>\n",
       "      <td>In the late 1940s I was given a delightful lit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35594</th>\n",
       "      <td>1536</td>\n",
       "      <td>Five teenagers escaped from Baton Rouge’s anti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35826</th>\n",
       "      <td>1121</td>\n",
       "      <td>A Lafayette woman has died after a Wednesday n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36093</th>\n",
       "      <td>402</td>\n",
       "      <td>Orleans Parish School Board members voted on T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id                                            content  relevant\n",
       "25630       30695  The April 11 death of a Shreveport inmatejustd...         1\n",
       "25933       29874  A Baton Rouge policeman at the center of an on...         1\n",
       "25976       29704  A Lafayette man filed a lawsuit in federal cou...         1\n",
       "25979       29704  A Lafayette man filed a lawsuit in federal cou...         1\n",
       "25980       29704  A Lafayette man filed a lawsuit in federal cou...         1\n",
       "...           ...                                                ...       ...\n",
       "35415        1880  The LSU Tigers are covering some familiar grou...         0\n",
       "35554        1614  In the late 1940s I was given a delightful lit...         0\n",
       "35594        1536  Five teenagers escaped from Baton Rouge’s anti...         0\n",
       "35826        1121  A Lafayette woman has died after a Wednesday n...         0\n",
       "36093         402  Orleans Parish School Board members voted on T...         0\n",
       "\n",
       "[126 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports\n",
    "- `extracted_keywords` in train/test/rem\n",
    "- sources in train/test/rem\n",
    "- authors in train/test/rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw_match</th>\n",
       "      <th>train_df</th>\n",
       "      <th>test_df</th>\n",
       "      <th>rem_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"NOPD\",\"officer\"]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"officer\",\"NOPD\",\"police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"officer\",\"Police\",\"NOPD\",\"police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"Officer\",\"police\",\"officer\",\"Police\"]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"officer\",\"police\"]</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[\"Officer\",\"police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[\"police\",\"Officer\"]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[\"terminated\"]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[\"terminated\",\"Police\"]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[\"officer\",\"Police\",\"police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[\"officer\",\"police\",\"NOPD\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[\"Police\",\"officer\",\"Officer\"]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[\"Officer\",\"Police\",\"police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[\"Officer\",\"police\",\"officer\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[\"officer\",\"Police\",\"NOPD\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[\"Police\",\"police\"]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[\"NOPD\",\"Officer\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[\"Officer\"]</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[\"NOPD\"]</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[\"NOPD\",\"Police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[\"officer\",\"NOPD\",\"Police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[\"officer\",\"Officer\"]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[\"NOPD\",\"officer\",\"Officer\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[\"NOPD\",\"police\",\"officer\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[\"Police\",\"officer\"]</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[\"terminated\",\"officer\"]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[\"Officer\",\"Police\"]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[\"Police\",\"officer\",\"police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[\"police\",\"NOPD\",\"officer\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[\"Officer\",\"officer\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[\"police\",\"Police\"]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[\"officer\",\"NOPD\"]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[\"officer\",\"Police\",\"Officer\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[\"Police\",\"Officer\",\"police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[\"officer\",\"police\",\"Police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[\"Officer\",\"officer\",\"Police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[\"Police\",\"NOPD\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[\"officer\"]</td>\n",
       "      <td>135.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1874.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[\"NOPD\",\"police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[\"Officer\",\"NOPD\"]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[\"Police\",\"terminated\"]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[\"police\",\"NOPD\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[\"NOPD\",\"officer\",\"Police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[\"Police\",\"police\",\"officer\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[\"police\",\"Police\",\"officer\"]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[\"police\",\"Police\",\"officer\",\"Officer\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[\"Police\",\"NOPD\",\"officer\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[\"police\",\"NOPD\",\"Police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[\"NOPD\",\"police\",\"Police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[\"police\"]</td>\n",
       "      <td>207.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[\"officer\",\"Police\"]</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[\"Police\"]</td>\n",
       "      <td>254.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[\"police\",\"officer\"]</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[\"terminated\",\"Officer\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[\"officer\",\"Police\",\"terminated\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[\"NOPD\",\"Police\",\"police\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[\"Police\",\"Officer\"]</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>[\"police\",\"officer\",\"Police\"]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   kw_match  train_df  test_df  rem_df\n",
       "0                        [\"NOPD\",\"officer\"]       2.0      NaN    24.0\n",
       "1               [\"officer\",\"NOPD\",\"police\"]       NaN      NaN     2.0\n",
       "2      [\"officer\",\"Police\",\"NOPD\",\"police\"]       NaN      NaN     1.0\n",
       "3   [\"Officer\",\"police\",\"officer\",\"Police\"]       1.0      NaN     1.0\n",
       "4                      [\"officer\",\"police\"]      13.0      NaN   169.0\n",
       "5                      [\"Officer\",\"police\"]       NaN      NaN    12.0\n",
       "6                      [\"police\",\"Officer\"]       1.0      1.0     9.0\n",
       "7                            [\"terminated\"]       4.0      2.0    85.0\n",
       "8                   [\"terminated\",\"Police\"]       2.0      NaN     NaN\n",
       "9             [\"officer\",\"Police\",\"police\"]       NaN      NaN     6.0\n",
       "10              [\"officer\",\"police\",\"NOPD\"]       NaN      NaN     2.0\n",
       "11           [\"Police\",\"officer\",\"Officer\"]       1.0      1.0     NaN\n",
       "12            [\"Officer\",\"Police\",\"police\"]       NaN      NaN     1.0\n",
       "13           [\"Officer\",\"police\",\"officer\"]       NaN      NaN     1.0\n",
       "14              [\"officer\",\"Police\",\"NOPD\"]       NaN      NaN     2.0\n",
       "15                      [\"Police\",\"police\"]       1.0      NaN    34.0\n",
       "16                       [\"NOPD\",\"Officer\"]       NaN      NaN     2.0\n",
       "17                              [\"Officer\"]      56.0      9.0   640.0\n",
       "18                                 [\"NOPD\"]      31.0      2.0   465.0\n",
       "19                        [\"NOPD\",\"Police\"]       NaN      NaN     8.0\n",
       "20              [\"officer\",\"NOPD\",\"Police\"]       NaN      NaN     1.0\n",
       "21                    [\"officer\",\"Officer\"]       2.0      NaN     8.0\n",
       "22             [\"NOPD\",\"officer\",\"Officer\"]       NaN      NaN     1.0\n",
       "23              [\"NOPD\",\"police\",\"officer\"]       NaN      NaN     1.0\n",
       "24                     [\"Police\",\"officer\"]      12.0      2.0   132.0\n",
       "25                 [\"terminated\",\"officer\"]       2.0      1.0     NaN\n",
       "26                     [\"Officer\",\"Police\"]       1.0      1.0    31.0\n",
       "27            [\"Police\",\"officer\",\"police\"]       NaN      NaN     6.0\n",
       "28              [\"police\",\"NOPD\",\"officer\"]       NaN      NaN     1.0\n",
       "29                    [\"Officer\",\"officer\"]       NaN      NaN     5.0\n",
       "30                      [\"police\",\"Police\"]      10.0      2.0    67.0\n",
       "31                       [\"officer\",\"NOPD\"]       1.0      NaN    38.0\n",
       "32           [\"officer\",\"Police\",\"Officer\"]       NaN      NaN     1.0\n",
       "33            [\"Police\",\"Officer\",\"police\"]       NaN      NaN     1.0\n",
       "34            [\"officer\",\"police\",\"Police\"]       NaN      NaN     2.0\n",
       "35           [\"Officer\",\"officer\",\"Police\"]       NaN      NaN     3.0\n",
       "36                        [\"Police\",\"NOPD\"]       NaN      NaN     3.0\n",
       "37                              [\"officer\"]     135.0     27.0  1874.0\n",
       "38                        [\"NOPD\",\"police\"]       NaN      NaN     9.0\n",
       "39                       [\"Officer\",\"NOPD\"]       2.0      NaN     2.0\n",
       "40                  [\"Police\",\"terminated\"]       2.0      NaN     NaN\n",
       "41                        [\"police\",\"NOPD\"]       NaN      NaN    14.0\n",
       "42              [\"NOPD\",\"officer\",\"Police\"]       NaN      NaN     1.0\n",
       "43            [\"Police\",\"police\",\"officer\"]       NaN      NaN     4.0\n",
       "44            [\"police\",\"Police\",\"officer\"]       1.0      1.0    10.0\n",
       "45  [\"police\",\"Police\",\"officer\",\"Officer\"]       NaN      NaN     1.0\n",
       "46              [\"Police\",\"NOPD\",\"officer\"]       NaN      NaN     1.0\n",
       "47               [\"police\",\"NOPD\",\"Police\"]       NaN      NaN     1.0\n",
       "48               [\"NOPD\",\"police\",\"Police\"]       NaN      NaN     1.0\n",
       "49                               [\"police\"]     207.0     33.0  2462.0\n",
       "50                     [\"officer\",\"Police\"]      28.0      6.0   122.0\n",
       "51                               [\"Police\"]     254.0     45.0  3250.0\n",
       "52                     [\"police\",\"officer\"]      13.0      4.0   246.0\n",
       "53                 [\"terminated\",\"Officer\"]       NaN      NaN     1.0\n",
       "54        [\"officer\",\"Police\",\"terminated\"]       NaN      NaN     1.0\n",
       "55               [\"NOPD\",\"Police\",\"police\"]       NaN      NaN     1.0\n",
       "56                     [\"Police\",\"Officer\"]       6.0      NaN    31.0\n",
       "57            [\"police\",\"officer\",\"Police\"]       1.0      NaN     3.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>train_df</th>\n",
       "      <th>test_df</th>\n",
       "      <th>rem_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>358.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10488.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>48.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>81.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>61.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>709.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>369.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source_id  train_df  test_df   rem_df\n",
       "0           1      17.0      4.0    457.0\n",
       "1           2     358.0     60.0  10488.0\n",
       "2           3       6.0      1.0    315.0\n",
       "3           4      13.0      1.0    328.0\n",
       "4           5       NaN      NaN    380.0\n",
       "5           6       NaN      NaN     36.0\n",
       "6           7      31.0      5.0   1446.0\n",
       "7           8      13.0      2.0   1062.0\n",
       "8           9       3.0      NaN    268.0\n",
       "9          10       6.0      NaN    447.0\n",
       "10         11       1.0      NaN    128.0\n",
       "11         12      16.0      7.0    839.0\n",
       "12         13      18.0      4.0    786.0\n",
       "13         14      11.0      2.0   2212.0\n",
       "14         15       4.0      1.0    770.0\n",
       "15         16      48.0     10.0   6096.0\n",
       "16         17      23.0      1.0    283.0\n",
       "17         18       NaN      1.0    188.0\n",
       "18         19      81.0      6.0   2845.0\n",
       "19         20       6.0      NaN    264.0\n",
       "20         21       NaN      NaN     11.0\n",
       "21         22       3.0      1.0    235.0\n",
       "22         23       NaN      1.0    180.0\n",
       "23         24       NaN      NaN     95.0\n",
       "24         25      25.0      5.0    158.0\n",
       "25         26       1.0      1.0    107.0\n",
       "26         27       4.0      1.0    133.0\n",
       "27         28       NaN      NaN    100.0\n",
       "28         29       1.0      NaN    113.0\n",
       "29         30      61.0     11.0   2560.0\n",
       "30         31       6.0      2.0    526.0\n",
       "31         32      18.0      5.0    709.0\n",
       "32         33      11.0      3.0    250.0\n",
       "33         34       4.0      2.0    369.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>train_df</th>\n",
       "      <th>test_df</th>\n",
       "      <th>rem_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Susan Hunt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE NEW ORLEANS ADVOCATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jonah Bostick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Julia Guilbeau</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Domenic Purdy, Special To The Advocate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>Aya Elamroussi, CNN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>John Walton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>Roger Ogden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>Kahn Swick &amp; Foti, LLC, Novavax, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>Jim Kleinpeter Contributing Writer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2198 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      author  train_df  test_df  rem_df\n",
       "0                                 Susan Hunt       NaN      NaN     1.0\n",
       "1                   THE NEW ORLEANS ADVOCATE       NaN      NaN     1.0\n",
       "2                              Jonah Bostick       NaN      NaN     8.0\n",
       "3                             Julia Guilbeau      10.0      2.0    23.0\n",
       "4     Domenic Purdy, Special To The Advocate       NaN      NaN     2.0\n",
       "...                                      ...       ...      ...     ...\n",
       "2193                     Aya Elamroussi, CNN       NaN      NaN     1.0\n",
       "2194                             John Walton       NaN      NaN     6.0\n",
       "2195                             Roger Ogden       NaN      NaN     1.0\n",
       "2196   Kahn Swick & Foti, LLC, Novavax, Inc.       NaN      NaN     1.0\n",
       "2197      Jim Kleinpeter Contributing Writer       NaN      NaN     2.0\n",
       "\n",
       "[2198 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing input data\n",
    "\n",
    "### `text_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full text shape:                                  (29707, 12)\n",
      "full text cols:\n",
      " ['created_at', 'link', 'guid', 'source_id', 'updated_at', 'content', 'published_date', 'id', 'title', 'is_processed', 'author', 'url']\n"
     ]
    }
   ],
   "source": [
    "pretty_print('full text shape:', text_df.shape)\n",
    "print('full text cols:\\n', list(text_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29707 entries, 0 to 29706\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   created_at      29707 non-null  object\n",
      " 1   link            29707 non-null  object\n",
      " 2   guid            29707 non-null  object\n",
      " 3   source_id       29707 non-null  int64 \n",
      " 4   updated_at      29707 non-null  object\n",
      " 5   content         29254 non-null  object\n",
      " 6   published_date  29707 non-null  object\n",
      " 7   id              29707 non-null  int64 \n",
      " 8   title           29707 non-null  object\n",
      " 9   is_processed    29707 non-null  bool  \n",
      " 10  author          27270 non-null  object\n",
      " 11  url             29707 non-null  object\n",
      "dtypes: bool(1), int64(2), object(9)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "text_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             distinct value count by col\n",
      "=======================================================\n",
      "created_at                                        29707\n",
      "link                                              29707\n",
      "guid                                              29698\n",
      "source_id                                         34\n",
      "updated_at                                        29707\n",
      "content                                           28581\n",
      "published_date                                    529\n",
      "id                                                29707\n",
      "title                                             28392\n",
      "is_processed                                      1\n",
      "author                                            2200\n",
      "url                                               29707\n"
     ]
    }
   ],
   "source": [
    "get_unique_report(text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sen_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched sen shape:                                (10470, 7)\n",
      "matched sen cols:\n",
      " ['id', 'created_at', 'updated_at', 'article_id', 'extracted_keywords', 'text', 'title']\n"
     ]
    }
   ],
   "source": [
    "pretty_print('matched sen shape:', sen_df.shape)\n",
    "print('matched sen cols:\\n', list(sen_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10470 entries, 0 to 10469\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  10470 non-null  int64 \n",
      " 1   created_at          10470 non-null  object\n",
      " 2   updated_at          10470 non-null  object\n",
      " 3   article_id          10470 non-null  int64 \n",
      " 4   extracted_keywords  10470 non-null  object\n",
      " 5   text                10470 non-null  object\n",
      " 6   title               10470 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 572.7+ KB\n"
     ]
    }
   ],
   "source": [
    "sen_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             distinct value count by col\n",
      "=======================================================\n",
      "id                                                10470\n",
      "created_at                                        10470\n",
      "updated_at                                        10470\n",
      "article_id                                        4323\n",
      "extracted_keywords                                60\n",
      "text                                              9925\n",
      "title                                             4179\n"
     ]
    }
   ],
   "source": [
    "get_unique_report(sen_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `true_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched true shape:                               (735, 3)\n",
      "matched true cols:\n",
      " ['id', 'matchedsentence_id', 'officer_id']\n"
     ]
    }
   ],
   "source": [
    "pretty_print('matched true shape:', true_df.shape)\n",
    "print('matched true cols:\\n', list(true_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 735 entries, 0 to 734\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   id                  735 non-null    int64\n",
      " 1   matchedsentence_id  735 non-null    int64\n",
      " 2   officer_id          735 non-null    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 17.4 KB\n"
     ]
    }
   ],
   "source": [
    "true_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             distinct value count by col\n",
      "=======================================================\n",
      "id                                                355\n",
      "matchedsentence_id                                479\n",
      "officer_id                                        355\n"
     ]
    }
   ],
   "source": [
    "get_unique_report(true_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
