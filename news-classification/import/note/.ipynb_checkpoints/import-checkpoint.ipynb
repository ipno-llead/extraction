{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import hashlib\n",
    "from numpy import nan as nan\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id tracking\n",
    "| df | article_id | matchedsentence_id | officer_id |\n",
    "|:--- | ---: | ---: | :---:|\n",
    "| text_df | text_df.id|X|X|\n",
    "| sen_df  | sen_df.article_id|sen_df.id|X|\n",
    "| true_df | X |true_df.matchedsentence_id|true_df.id|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support methods for notebook version\n",
    "def get_unique_report(df):\n",
    "    cols = list(df.columns)\n",
    "    print('             distinct value count by col')\n",
    "    print('=======================================================')\n",
    "    for col in cols:\n",
    "        pretty_print(col, len(df[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--included\")\n",
    "    parser.add_argument(\"--true\")\n",
    "    parser.add_argument(\"--text\")\n",
    "    parser.add_argument(\"--output\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def get_logging(logname):\n",
    "        logging.basicConfig(level=logging.DEBUG,\n",
    "                            format='%(asctime)s %(levelname)s %(message)s',\n",
    "                            handlers=[logging.FileHandler(logname),\n",
    "                            logging.StreamHandler()])\n",
    "\n",
    "\n",
    "def open_gz(f):\n",
    "    return pd.read_csv(f, compression='gzip')\n",
    "\n",
    "\n",
    "def pretty_str(label, a, b=False, newline=False):\n",
    "    if newline:\n",
    "        if not b:\n",
    "            return '{:50}{}{}'.format(label, a, '\\n')\n",
    "        else:\n",
    "            return '{:50}{:10}{:10}{}'.format(label, a, b, '\\n')\n",
    "    if b:\n",
    "        return '{:50}{:10}{:10}'.format(label, a, b)\n",
    "    return '{:50}{}'.format(label, a)\n",
    "\n",
    "\n",
    "def check_asserts(text_df, sen_df, true_df):\n",
    "    assert text_df.shape == (29707, 12)\n",
    "    assert sen_df.shape == (10470, 7)\n",
    "    assert true_df.shape == (735, 3)\n",
    "    assert all(text_df.columns == ['created_at', 'link', 'guid', 'source_id', \\\n",
    "                                   'updated_at', 'content', 'published_date', 'id', \\\n",
    "                                   'title', 'is_processed', 'author', 'url'])\n",
    "    assert all(sen_df.columns == ['id', 'created_at', 'updated_at', 'article_id', \n",
    "                                   'extracted_keywords', 'text', 'title'])\n",
    "    assert all(true_df.columns == ['id', 'matchedsentence_id', 'officer_id'])\n",
    "    most = set(text_df.id.unique())\n",
    "    mid = set(sen_df.id.unique())\n",
    "    least = set(true_df.id.unique())\n",
    "    assert len(least) < len(mid) < len(most)\n",
    "    assert len(most.intersection(mid)) == 9891\n",
    "    assert all(true_df.id == true_df.officer_id)   # what does it mean that this is true? will it always?\n",
    "    pairs = set()\n",
    "    for tup in true_df.itertuples():\n",
    "        pairs.add((tup.id, tup.matchedsentence_id))\n",
    "    assert len(pairs) == true_df.shape[0]\n",
    "    articles = text_df.id.unique()\n",
    "    matched = sen_df.article_id.unique()\n",
    "    assert len(matched) < len(articles)\n",
    "    assert len(articles) == 29707\n",
    "    assert len(matched) == 4323\n",
    "    for match in matched:\n",
    "        assert match in articles\n",
    "    matched_sen = sen_df.id.unique()\n",
    "    true_match_sen = true_df.matchedsentence_id.unique()\n",
    "    true_match_off = true_df.id.unique()\n",
    "    assert len(true_match_sen) < len(matched_sen)\n",
    "    assert len(matched_sen) == 10470\n",
    "    assert len(true_match_sen) == 479\n",
    "    for match in true_match_sen:\n",
    "        assert match in matched_sen\n",
    "\n",
    "\n",
    "def format_extracted_str(list_str):\n",
    "    if list_str is not None:\n",
    "        clean = list_str.replace('[', '').replace(']', '').replace('\"', '').lower()\n",
    "        if ',' in clean:\n",
    "            return str({val for val in clean.split(',')})\n",
    "        return str({clean})\n",
    "    return None\n",
    "\n",
    "\n",
    "def prep_dfs(text_df, sen_df, true_df):\n",
    "    less_text = text_df.loc[:, ['id', 'source_id', 'author', 'title', 'content']]\n",
    "    temp = less_text\n",
    "    less_text = temp.rename(columns={'id':'article_id'})\n",
    "    less_sen = sen_df.loc[:, ['id', 'article_id', 'text']]\n",
    "    temp = less_sen\n",
    "    less_sen = temp.rename(columns={'id':'matchedsentence_id'})\n",
    "    less_sen['extracted_keywords'] = sen_df.extracted_keywords.apply(format_extracted_str)\n",
    "    less_sen['kw_match'] = [1 for val in range(less_sen.shape[0])]\n",
    "    less_true = true_df.loc[:, ['officer_id', 'matchedsentence_id']]\n",
    "    less_true['relevant'] = [1 for val in range(less_true.shape[0])]\n",
    "    return less_text, less_sen, less_true\n",
    "\n",
    "\n",
    "def merge_dfs(less_text, less_sen, less_true):\n",
    "    less_text = less_text.set_index('article_id')\n",
    "    less_sen = less_sen.set_index('article_id')\n",
    "    out = less_text.join(less_sen, on='article_id', how='outer').reset_index().set_index('matchedsentence_id')\n",
    "    temp = less_true\n",
    "    less_true = temp.set_index('matchedsentence_id')\n",
    "    out = out.join(less_true, on='matchedsentence_id', how='outer')\n",
    "    out = out.reset_index()\n",
    "    out.kw_match.fillna(value=0, axis=0, inplace=True)\n",
    "    out.relevant.fillna(value=0, axis=0, inplace=True)\n",
    "    temp = out\n",
    "    out['kw_match'] = temp.kw_match.astype(int)\n",
    "    out['relevant'] = temp.relevant.astype(int)\n",
    "    return out\n",
    "\n",
    "\n",
    "# this method is called when relevant_articles and irrelevant_articles are not disjoint sets\n",
    "# resolves conflict by upgrading all occurances of an article_id in relevant_articles to relevant\n",
    "# ie. a sentence from an article is matched to an officer and appears in matchedsentence_officers data\n",
    "#     a different sentence from same article is not matched and deemed irrelevant, appears in matchedsentence data\n",
    "#     conflict occurs when datasets merged\n",
    "def correct_relevant(df):\n",
    "    copy = df.copy()\n",
    "    relevant = copy.loc[copy.relevant == 1].article_id.unique().tolist()\n",
    "    copy.loc[copy.article_id.isin(relevant), 'relevant'] = 1\n",
    "    return copy\n",
    "\n",
    "\n",
    "# This method builds the POSITIVE cases: keyword matched AND article relevant (per Rajiv)\n",
    "def prep_pos_train_test(df, train_perc=0.80, test_perc=0.20):\n",
    "    id_mask = (df.officer_id.notnull())\n",
    "    possible = df.loc[id_mask].article_id.unique().tolist()\n",
    "    train_list, test_list = train_test_split(possible, test_size=test_perc, train_size=train_perc, shuffle=True)\n",
    "    assert set(train_list).isdisjoint(set(test_list))\n",
    "    return train_list, test_list\n",
    "\n",
    "\n",
    "# This method builds the NEGATIVE cases: keyword matched but not relevant\n",
    "def prep_neg_train_test(df, pos_rate, curr_train_n, curr_test_n):\n",
    "    assert 0 < pos_rate <= 0.5\n",
    "    target_train = ceil(curr_train_n/pos_rate)\n",
    "    target_test = ceil(curr_test_n/pos_rate)\n",
    "    needed_train = target_train - curr_train_n\n",
    "    needed_test = target_test - curr_test_n\n",
    "    id_mask = (df.kw_match == 1) & (df.officer_id.isnull())\n",
    "    possible = df.loc[id_mask].article_id.unique().tolist()\n",
    "    assert needed_train + needed_test <= len(possible)\n",
    "    train_list, test_list = train_test_split(possible, test_size=needed_test, train_size=needed_train, shuffle=True)\n",
    "    assert set(train_list).isdisjoint(set(test_list))\n",
    "    return train_list, test_list\n",
    "\n",
    "\n",
    "def make_train_test_cols(df, pos_rate):\n",
    "    copy = df.copy()\n",
    "    # get pos/neg and train/test indice sets\n",
    "    pos_train_idx, pos_test_idx = prep_pos_train_test(copy)\n",
    "    neg_train_idx, neg_test_idx = prep_neg_train_test(copy, pos_rate, len(pos_train_idx), len(pos_test_idx))\n",
    "    # train\n",
    "    train_idx = pos_train_idx + neg_train_idx\n",
    "    copy['train'] = [1 if val in train_idx else 0 for val in copy.article_id.values]\n",
    "    # test\n",
    "    test_idx = pos_test_idx + neg_test_idx\n",
    "    copy['test'] = [1 if val in test_idx else 0 for val in copy.article_id.values]\n",
    "    return copy[['article_id', 'matchedsentence_id', 'source_id', 'author', 'title', 'text', \\\n",
    "                'content', 'officer_id', 'extracted_keywords', 'kw_match', 'relevant', 'train', 'test']]\n",
    "\n",
    "\n",
    "def make_train_test_df(df):\n",
    "    full = df.loc[((df.train == 1) | (df.test == 1)), ['article_id', 'content', 'relevant', 'test']]\n",
    "    full.drop_duplicates(subset='article_id', inplace=True)\n",
    "    return full\n",
    "\n",
    "\n",
    "# Since out.kw_match = out.relevant_count + out.irrelevant_count, and relevant can't be true without kw_match,\n",
    "# (out.relevant_count) / (out.kw_match) should be the proportion of relevant samples given kw_match for col value\n",
    "def make_report(df, col):\n",
    "    kw_match_vc = df.loc[df.kw_match == 1][col].value_counts().to_dict()\n",
    "    relevant_vc = df.loc[df.relevant == 1][col].value_counts().to_dict()\n",
    "    irrelevant_match_vc = df.loc[(df.kw_match == 1) & (df.relevant != 1)][col].value_counts().to_dict()\n",
    "    kws = set(list(kw_match_vc.keys()) + list(relevant_vc.keys()) + list(irrelevant_match_vc.keys()))\n",
    "    out_data = {kw:{} for kw in kws}\n",
    "    for kw in kws:\n",
    "        if kw in kw_match_vc:\n",
    "            out_data[kw]['kw_match'] = kw_match_vc[kw]\n",
    "        else:\n",
    "            out_data[kw]['kw_match'] = 0\n",
    "        if kw in relevant_vc:\n",
    "            out_data[kw]['relevant_count'] = relevant_vc[kw]\n",
    "        else:\n",
    "            out_data[kw]['relevant_count'] = 0\n",
    "    out = pd.DataFrame.from_dict(out_data).T.reset_index().rename(columns={'index':col})\n",
    "    out['relevant_perc'] = round((out.relevant_count) / (out.kw_match), 3)\n",
    "    return out\n",
    "\n",
    "\n",
    "def make_final_logs(text_df, sen_df, true_df, train_test_df, merged):\n",
    "    print('I/O id summary')\n",
    "    print('=======================================================================')\n",
    "    print(pretty_str('all kw_match articles in raw data:', True))      # asserted by check_asserts()\n",
    "    print(pretty_str('all matchedsentences in kw_match data:', True))\n",
    "    print(pretty_str('unique articles:', len(text_df.id.unique())))\n",
    "    print(pretty_str('unique articles w/ kw match:', len(sen_df.article_id.unique())))\n",
    "    print(pretty_str('unique matched sentences:', len(sen_df.id.unique())))\n",
    "    print(pretty_str('unique matched sentences relevant:', len(true_df.matchedsentence_id.unique())))\n",
    "    print(pretty_str('unique matched officers relevant:', len(true_df.id.unique())))\n",
    "    print(pretty_str('unique articles in train_test:', len(train_test_df.article_id.unique()), newline=True))\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO OUTPUT:\n",
    "# 1. article_id (given in data)\n",
    "# 2. article text (given in data)\n",
    "# 3. relevant (if article in true_df)\n",
    "# 4. test (if article is reserved for testing model)     Per TS: 500 train, 100 test for initial train\n",
    "# (may add cols like author or title)\n",
    "\n",
    "# CONSIDERING\n",
    "# correct_kw_match? does article_id conflict also occur with matchedsentence_id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', 'raise')\n",
    "# __main__\n",
    "\n",
    "# newsarticle: initial dataset\n",
    "#    - has all the data related to the article as it was pulled into feed\n",
    "# matchedsentence: initial keyword filter\n",
    "#    - has all the data related to every article with at least one sentence matching a keyword\n",
    "# matchedsentence_officers: manual filter (Rajiv)\n",
    "#    - has select columns linking identified officer badges and articles confirmed relevant by Rajiv\n",
    "# NOTE: If an article is not in the manual filter set, it is not relevant\n",
    "news_text_f = '../input/news_articles_newsarticle.csv.gz'\n",
    "news_included_f = '../input/news_articles_matchedsentence.csv.gz'\n",
    "news_true_f = '../input/news_articles_matchedsentence_officers.csv.gz'\n",
    "\n",
    "text_df = open_gz(news_text_f)\n",
    "sen_df = open_gz(news_included_f)\n",
    "true_df = open_gz(news_true_f)\n",
    "check_asserts(text_df, sen_df, true_df)\n",
    "\n",
    "less_text, less_sen, less_true = prep_dfs(text_df, sen_df, true_df)\n",
    "merged = merge_dfs(less_text, less_sen, less_true)\n",
    "# report lost columns\n",
    "print()\n",
    "print('columns ignored by import')\n",
    "print('=======================================================================')\n",
    "all_cols = set(text_df.columns.tolist() + sen_df.columns.tolist() + true_df.columns.tolist())\n",
    "kept = set(merged.columns)\n",
    "not_kept = all_cols.difference(kept)\n",
    "not_kept.remove('id')\n",
    "print(str(not_kept)+'\\n')\n",
    "\n",
    "# make sure every article_id has a corresponding 'relevant' value\n",
    "all_ids = set(merged.article_id.unique())\n",
    "relevant_articles = set(merged.loc[(merged.relevant == 1)].article_id.unique())\n",
    "irrelevant_articles = set(merged.loc[(merged.relevant == 0)].article_id.unique())\n",
    "rel_vals = relevant_articles.union(irrelevant_articles)\n",
    "assert all_ids.difference(rel_vals) == set()\n",
    "overlap = relevant_articles.intersection(irrelevant_articles)\n",
    "print('relevant && irrelevant articles check')\n",
    "print('=======================================================================')\n",
    "print(pretty_str('unique relevant articles:', len(relevant_articles)))\n",
    "print(pretty_str('unique irrelevant articles:', len(irrelevant_articles)))\n",
    "# check for conflicting 'relevant' values, correct if present\n",
    "print(pretty_str('relevant and irrelevant disjoint:', overlap == set()))\n",
    "if overlap != set():\n",
    "    print(pretty_str('size of overlap:', len(overlap)))\n",
    "    temp = merged\n",
    "    merged = correct_relevant(temp)\n",
    "    print(pretty_str('amended relevant column:', True, newline=True))\n",
    "\n",
    "# Per TS, starting train/test size should be roughly 500/100\n",
    "# ASSUMES initial balance of 50/50 positive/negative\n",
    "# proceed with generating training data\n",
    "merged = make_train_test_cols(merged, pos_rate=0.5)\n",
    "train_test_df = make_train_test_df(merged)\n",
    "print('train, test summary')\n",
    "print('=======================================================================')\n",
    "train = train_test_df.loc[train_test_df.test == 0, ['article_id', 'content', 'relevant']]\n",
    "test = train_test_df.loc[train_test_df.test == 1, ['article_id', 'content', 'relevant']]\n",
    "train_n = train.article_id.count()\n",
    "test_n = test.article_id.count()\n",
    "assert train_n + test_n == train_test_df.shape[0]\n",
    "train_pos = train.loc[train.relevant == 1].article_id.count()\n",
    "test_pos = test.loc[test.relevant == 1].article_id.count()\n",
    "train_neg = train_n - train_pos\n",
    "test_neg = test_n - test_pos\n",
    "print(f'{train_n} datapoints available for training with balance: {train_pos}/{train_neg} (pos/neg)')\n",
    "print(f'{test_n} datapoints available for testing with balance: {test_pos}/{test_neg} (pos/neg)\\n')\n",
    "print('train info')\n",
    "print('=======================================================================')\n",
    "train.info()\n",
    "print('\\ntest info')\n",
    "print('=======================================================================')\n",
    "test.info()\n",
    "print()\n",
    "\n",
    "# writing a subset of merged to use as pre-training data\n",
    "temp = merged.loc[:, ['article_id', 'title', 'content']].drop_duplicates(subset='article_id')\n",
    "assert len(temp.article_id.unique()) == temp.shape[0]\n",
    "news = temp.sample(temp.shape[0]).reset_index(drop=True)\n",
    "#merged.to_parquet('../output/merged.parquet')\n",
    "\n",
    "assert make_final_logs(text_df, sen_df, true_df, train_test_df, merged)\n",
    "\n",
    "# generate keyword report (source_id, author also helpful reports)\n",
    "kw_report = make_report(merged, 'extracted_keywords')\n",
    "print('keyword report')\n",
    "print('=======================================================================')\n",
    "print('{:50}{:15}{:10}'.format('extracted_keywords', 'relevant_perc', 'kw_match'))\n",
    "sorted_kw_report = kw_report[['extracted_keywords', 'relevant_perc', 'kw_match']].sort_values(by='relevant_perc', ascending=False)\n",
    "for tup in sorted_kw_report.itertuples():\n",
    "    print(pretty_str(tup.extracted_keywords+':', tup.relevant_perc, b=tup.kw_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated true pos_rate\n",
    "kw_match_n = merged.loc[merged.kw_match==1].article_id.count()\n",
    "relevant_n = merged.loc[merged.relevant==1].article_id.count()\n",
    "round(relevant_n/kw_match_n, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any articles that contain a matched sentence but kw_match isn't True?\n",
    "match = set(merged.loc[merged.kw_match == 1].article_id.unique())\n",
    "no_match = set(merged.loc[merged.kw_match == 0].article_id.unique())\n",
    "match.intersection(no_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outgoing train_test asserts:\n",
    "#    1. No article_id or content is missing from either train or test sets\n",
    "#    2. No article_id or content appears in both train AND test sets\n",
    "#    3. Every article_id has a relevant, test value\n",
    "#    - Could assert pos_rate with margin of error +- 0.1\n",
    "\n",
    "# outgoing rule 1\n",
    "assert train_test_df.loc[train_test_df.article_id.isnull()].shape == (0,4)\n",
    "assert train_test_df.loc[train_test_df.content.isnull()].shape == (0,4)\n",
    "\n",
    "# outgoing rule 2\n",
    "train_articles = set(train_test_df.loc[train_test_df.test == 0].article_id.unique())\n",
    "test_articles = set(train_test_df.loc[train_test_df.test == 1].article_id.unique())\n",
    "assert train_articles.isdisjoint(test_articles)\n",
    "train_contents = set(train_test_df.loc[train_test_df.test == 0].content.unique())\n",
    "test_contents = set(train_test_df.loc[train_test_df.test == 1].content.unique())\n",
    "print(train_contents.isdisjoint(test_contents))\n",
    "\n",
    "# caveat to rule 2: duplicate \n",
    "article_ids = set(train_test_df.article_id.unique())\n",
    "contents = set(train_test_df.content.unique())\n",
    "print(train_test_df.shape)\n",
    "assert len(article_ids) == train_test_df.shape[0]\n",
    "print(len(contents))\n",
    "\n",
    "# outgoing rule 3\n",
    "assert train_test_df.loc[train_test_df.relevant.isnull()].shape == (0,4)\n",
    "assert train_test_df.loc[train_test_df.test.isnull()].shape == (0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rule 1 violation: Why is unique content < number of rows\n",
    "dup_content = train_test_df.loc[train_test_df.duplicated(subset='content')].content.values.tolist()\n",
    "if dup_content != []:\n",
    "    dup_content_df = train_test_df.loc[train_test_df.content.isin(dup_content)]\n",
    "    print('duplicated content shape:', dup_content_df.shape)\n",
    "    dup_content_ids = dup_content_df.article_id.unique().tolist()\n",
    "    print('article_ids in train_test_df implicated by dup_content:', len(dup_content_ids))\n",
    "    all_dup_content_ids = merged.loc[merged.article_id.isin(dup_content_ids)].article_id.unique().tolist()\n",
    "    print('article_ids in merged implicated by dup_content:', len(all_dup_content_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule 1 violation: Why is unique content < number of rows\n",
    "dup_content = merged.loc[merged.duplicated(subset='content')].content.values.tolist()\n",
    "if dup_content != []:\n",
    "    dup_content_df = merged.loc[merged.content.isin(dup_content)]\n",
    "    print('duplicated content shape:', dup_content_df.shape)\n",
    "    dup_content_ids = dup_content_df.article_id.unique().tolist()\n",
    "    print('article_ids in merged implicated by dup_content:', len(dup_content_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news.loc[news.article_id == 20541].content.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVED TO OWN SCRIPT\n",
    "# Rule 1 violation: Why is unique content < number of rows\n",
    "#dup_title = merged.loc[merged.duplicated(subset='title')].title.values.tolist()\n",
    "#if dup_title != []:\n",
    "#    dup_title_df = merged.loc[merged.title.isin(dup_title)]\n",
    "#    print('duplicated title shape:', dup_title_df.shape)\n",
    "#    dup_title_ids = dup_title_df.article_id.unique().tolist()\n",
    "#    print('article_ids in merged implicated by dup_title:', len(dup_title_ids))\n",
    "#    dup_title_ids = dup_title_df.loc[dup_title_df.content].article_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are matchedsentence_ids unique by text, or by text in unique article?\n",
    "dup_text = merged.loc[merged.duplicated(subset='text')].text.unique().tolist()\n",
    "dup_text_df = merged.loc[merged.text.isin(dup_text)]\n",
    "\n",
    "dup_text_ids = {}\n",
    "for tup in dup_text_df.itertuples():\n",
    "    this_art_id = tup.article_id\n",
    "    this_mat_id = tup.matchedsentence_id\n",
    "    if str(tup.text) != 'nan':\n",
    "        this_art_id = tup.article_id\n",
    "        this_mat_id = tup.matchedsentence_id\n",
    "        if tup.text not in dup_text_ids:\n",
    "            dup_text_ids[tup.text] = {'article_id': [this_art_id], 'matchedsentence_id': [this_mat_id]}\n",
    "        else:\n",
    "            if this_art_id not in dup_text_ids[tup.text]['article_id']:\n",
    "                dup_text_ids[tup.text]['article_id'].append(this_art_id)\n",
    "            if this_mat_id not in dup_text_ids[tup.text]['matchedsentence_id']:\n",
    "                dup_text_ids[tup.text]['matchedsentence_id'].append(this_mat_id)\n",
    "\n",
    "multiple_art = 0\n",
    "for text, id_dict in dup_text_ids.items():\n",
    "    if (len(id_dict['article_id']) > 1):\n",
    "        multiple_art += 1\n",
    "        # suspect sentences found in distinct articles are processed as distinct sentences\n",
    "        # matchedsentence_id only refers to uniqueness within article, not in database\n",
    "        assert len(id_dict['article_id']) == len(id_dict['matchedsentence_id'])\n",
    "\n",
    "print('duplicate text shape:\\t\\t\\t', dup_text_df.shape)\n",
    "print('unique text samples duplicated:\\t\\t', len(dup_text_ids))\n",
    "print('articles affected by duplicate text:\\t', multiple_art)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports\n",
    "- `extracted_keywords` in train/test/rem\n",
    "- sources in train/test/rem\n",
    "- authors in train/test/rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_report.sort_values(by='relevant_perc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kw_report[['extracted_keywords', 'relevant_perc']].sort_values(by='relevant_perc', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_report.sort_values(by='relevant_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_report.sort_values(by='relevant_count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing input data\n",
    "\n",
    "### `text_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretty_print('full text shape:', text_df.shape)\n",
    "print('full text cols:\\n', list(text_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_unique_report(text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sen_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretty_print('matched sen shape:', sen_df.shape)\n",
    "print('matched sen cols:\\n', list(sen_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_unique_report(sen_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `true_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretty_print('matched true shape:', true_df.shape)\n",
    "print('matched true cols:\\n', list(true_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_unique_report(true_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
