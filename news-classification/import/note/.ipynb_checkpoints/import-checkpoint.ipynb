{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "from numpy import nan as nan\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['title'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j_/497vxglx1kz07md2f3v37jlw0000gn/T/ipykernel_1828/978192088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'article_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1095\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['title'] not in index\""
     ]
    }
   ],
   "source": [
    "merged.loc[:, ['article_id', 'title', 'content']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id tracking\n",
    "| df | article_id | matchedsentence_id | officer_id |\n",
    "|:--- | ---: | ---: | :---:|\n",
    "| text_df | text_df.id|X|X|\n",
    "| sen_df  | sen_df.article_id|sen_df.id|X|\n",
    "| true_df | X |true_df.matchedsentence_id|true_df.id|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support methods for notebook version\n",
    "def get_unique_report(df):\n",
    "    cols = list(df.columns)\n",
    "    print('             distinct value count by col')\n",
    "    print('=======================================================')\n",
    "    for col in cols:\n",
    "        pretty_print(col, len(df[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--included\")\n",
    "    parser.add_argument(\"--true\")\n",
    "    parser.add_argument(\"--text\")\n",
    "    parser.add_argument(\"--output\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def get_logging(logname):\n",
    "        logging.basicConfig(level=logging.DEBUG,\n",
    "                            format='%(asctime)s %(levelname)s %(message)s',\n",
    "                            handlers=[logging.FileHandler(logname),\n",
    "                            logging.StreamHandler()])\n",
    "\n",
    "\n",
    "def open_gz(f):\n",
    "    return pd.read_csv(f, compression='gzip')\n",
    "\n",
    "\n",
    "def pretty_str(label, a, b=False, newline=False):\n",
    "    if newline:\n",
    "        if not b:\n",
    "            return '{:50}{}{}'.format(label, a, '\\n')\n",
    "        else:\n",
    "            return '{:50}{:10}{:10}{}'.format(label, a, b, '\\n')\n",
    "    if b:\n",
    "        return '{:50}{:10}{:10}'.format(label, a, b)\n",
    "    return '{:50}{}'.format(label, a)\n",
    "\n",
    "\n",
    "def check_asserts(text_df, sen_df, true_df):\n",
    "    assert text_df.shape == (29707, 12)\n",
    "    assert sen_df.shape == (10470, 7)\n",
    "    assert true_df.shape == (735, 3)\n",
    "    assert all(text_df.columns == ['created_at', 'link', 'guid', 'source_id', \\\n",
    "                                   'updated_at', 'content', 'published_date', 'id', \\\n",
    "                                   'title', 'is_processed', 'author', 'url'])\n",
    "    assert all(sen_df.columns == ['id', 'created_at', 'updated_at', 'article_id', \n",
    "                                   'extracted_keywords', 'text', 'title'])\n",
    "    assert all(true_df.columns == ['id', 'matchedsentence_id', 'officer_id'])\n",
    "    most = set(text_df.id.unique())\n",
    "    mid = set(sen_df.id.unique())\n",
    "    least = set(true_df.id.unique())\n",
    "    assert len(least) < len(mid) < len(most)\n",
    "    assert len(most.intersection(mid)) == 9891\n",
    "    assert all(true_df.id == true_df.officer_id)   # what does it mean that this is true? will it always?\n",
    "    pairs = set()\n",
    "    for tup in true_df.itertuples():\n",
    "        pairs.add((tup.id, tup.matchedsentence_id))\n",
    "    assert len(pairs) == true_df.shape[0]\n",
    "    articles = text_df.id.unique()\n",
    "    matched = sen_df.article_id.unique()\n",
    "    assert len(matched) < len(articles)\n",
    "    assert len(articles) == 29707\n",
    "    assert len(matched) == 4323\n",
    "    for match in matched:\n",
    "        assert match in articles\n",
    "    matched_sen = sen_df.id.unique()\n",
    "    true_match_sen = true_df.matchedsentence_id.unique()\n",
    "    true_match_off = true_df.id.unique()\n",
    "    assert len(true_match_sen) < len(matched_sen)\n",
    "    assert len(matched_sen) == 10470\n",
    "    assert len(true_match_sen) == 479\n",
    "    for match in true_match_sen:\n",
    "        assert match in matched_sen\n",
    "\n",
    "\n",
    "def format_extracted_str(list_str):\n",
    "    if list_str is not None:\n",
    "        clean = list_str.replace('[', '').replace(']', '').replace('\"', '').lower()\n",
    "        if ',' in clean:\n",
    "            return str({val for val in clean.split(',')})\n",
    "        return str({clean})\n",
    "    return None\n",
    "\n",
    "\n",
    "def prep_dfs(text_df, sen_df, true_df):\n",
    "    less_text = text_df.loc[:, ['id', 'source_id', 'author', 'title', 'content']]\n",
    "    temp = less_text\n",
    "    less_text = temp.rename(columns={'id':'article_id'})\n",
    "    less_sen = sen_df.loc[:, ['id', 'article_id', 'text']]\n",
    "    temp = less_sen\n",
    "    less_sen = temp.rename(columns={'id':'matchedsentence_id'})\n",
    "    less_sen['extracted_keywords'] = sen_df.extracted_keywords.apply(format_extracted_str)\n",
    "    less_sen['kw_match'] = [1 for val in range(less_sen.shape[0])]\n",
    "    less_true = true_df.loc[:, ['officer_id', 'matchedsentence_id']]\n",
    "    less_true['relevant'] = [1 for val in range(less_true.shape[0])]\n",
    "    return less_text, less_sen, less_true\n",
    "\n",
    "\n",
    "def merge_dfs(less_text, less_sen, less_true):\n",
    "    less_text = less_text.set_index('article_id')\n",
    "    less_sen = less_sen.set_index('article_id')\n",
    "    out = less_text.join(less_sen, on='article_id', how='outer').reset_index().set_index('matchedsentence_id')\n",
    "    temp = less_true\n",
    "    less_true = temp.set_index('matchedsentence_id')\n",
    "    out = out.join(less_true, on='matchedsentence_id', how='outer')\n",
    "    out = out.reset_index()\n",
    "    out.kw_match.fillna(value=0, axis=0, inplace=True)\n",
    "    out.relevant.fillna(value=0, axis=0, inplace=True)\n",
    "    temp = out\n",
    "    out['kw_match'] = temp.kw_match.astype(int)\n",
    "    out['relevant'] = temp.relevant.astype(int)\n",
    "    return out\n",
    "\n",
    "\n",
    "# this method is called when relevant_articles and irrelevant_articles are not disjoint sets\n",
    "# resolves conflict by upgrading all occurances of an article_id in relevant_articles to relevant\n",
    "# ie. a sentence from an article is matched to an officer and appears in matchedsentence_officers data\n",
    "#     a different sentence from same article is not matched and deemed irrelevant, appears in matchedsentence data\n",
    "#     conflict occurs when datasets merged\n",
    "def correct_relevant(df):\n",
    "    copy = df.copy()\n",
    "    relevant = copy.loc[copy.relevant == 1].article_id.unique().tolist()\n",
    "    copy.loc[copy.article_id.isin(relevant), 'relevant'] = 1\n",
    "    return copy\n",
    "\n",
    "\n",
    "# This method builds the POSITIVE cases: keyword matched AND article relevant (per Rajiv)\n",
    "def prep_pos_train_test(df, train_perc=0.80, test_perc=0.20):\n",
    "    id_mask = (df.officer_id.notnull())\n",
    "    possible = df.loc[id_mask].article_id.unique().tolist()\n",
    "    train_list, test_list = train_test_split(possible, test_size=test_perc, train_size=train_perc, shuffle=True)\n",
    "    assert set(train_list).isdisjoint(set(test_list))\n",
    "    return train_list, test_list\n",
    "\n",
    "\n",
    "# This method builds the NEGATIVE cases: keyword matched but not relevant\n",
    "def prep_neg_train_test(df, pos_rate, curr_train_n, curr_test_n):\n",
    "    assert 0 < pos_rate <= 0.5\n",
    "    target_train = ceil(curr_train_n/pos_rate)\n",
    "    target_test = ceil(curr_test_n/pos_rate)\n",
    "    needed_train = target_train - curr_train_n\n",
    "    needed_test = target_test - curr_test_n\n",
    "    id_mask = (df.kw_match == 1) & (df.officer_id.isnull())\n",
    "    possible = df.loc[id_mask].article_id.unique().tolist()\n",
    "    assert needed_train + needed_test <= len(possible)\n",
    "    train_list, test_list = train_test_split(possible, test_size=needed_test, train_size=needed_train, shuffle=True)\n",
    "    assert set(train_list).isdisjoint(set(test_list))\n",
    "    return train_list, test_list\n",
    "\n",
    "\n",
    "def make_train_test_cols(df, pos_rate):\n",
    "    copy = df.copy()\n",
    "    # get pos/neg and train/test indice sets\n",
    "    pos_train_idx, pos_test_idx = prep_pos_train_test(copy)\n",
    "    neg_train_idx, neg_test_idx = prep_neg_train_test(copy, pos_rate, len(pos_train_idx), len(pos_test_idx))\n",
    "    # train\n",
    "    train_idx = pos_train_idx + neg_train_idx\n",
    "    copy['train'] = [1 if val in train_idx else 0 for val in copy.article_id.values]\n",
    "    # test\n",
    "    test_idx = pos_test_idx + neg_test_idx\n",
    "    copy['test'] = [1 if val in test_idx else 0 for val in copy.article_id.values]\n",
    "    return copy[['article_id', 'matchedsentence_id', 'source_id', 'author', 'title', 'text', \\\n",
    "                'content', 'officer_id', 'extracted_keywords', 'kw_match', 'relevant', 'train', 'test']]\n",
    "\n",
    "\n",
    "def make_train_test_df(df):\n",
    "    full = df.loc[((df.train == 1) | (df.test == 1)), ['article_id', 'content', 'relevant', 'test']]\n",
    "    full.drop_duplicates(subset='article_id', inplace=True)\n",
    "    return full\n",
    "\n",
    "\n",
    "# Since out.kw_match = out.relevant_count + out.irrelevant_count, and relevant can't be true without kw_match,\n",
    "# (out.relevant_count) / (out.kw_match) should be the proportion of relevant samples given kw_match for col value\n",
    "def make_report(df, col):\n",
    "    kw_match_vc = df.loc[df.kw_match == 1][col].value_counts().to_dict()\n",
    "    relevant_vc = df.loc[df.relevant == 1][col].value_counts().to_dict()\n",
    "    irrelevant_match_vc = df.loc[(df.kw_match == 1) & (df.relevant != 1)][col].value_counts().to_dict()\n",
    "    kws = set(list(kw_match_vc.keys()) + list(relevant_vc.keys()) + list(irrelevant_match_vc.keys()))\n",
    "    out_data = {kw:{} for kw in kws}\n",
    "    for kw in kws:\n",
    "        if kw in kw_match_vc:\n",
    "            out_data[kw]['kw_match'] = kw_match_vc[kw]\n",
    "        else:\n",
    "            out_data[kw]['kw_match'] = 0\n",
    "        if kw in relevant_vc:\n",
    "            out_data[kw]['relevant_count'] = relevant_vc[kw]\n",
    "        else:\n",
    "            out_data[kw]['relevant_count'] = 0\n",
    "    out = pd.DataFrame.from_dict(out_data).T.reset_index().rename(columns={'index':col})\n",
    "    out['relevant_perc'] = round((out.relevant_count) / (out.kw_match), 3)\n",
    "    return out\n",
    "\n",
    "\n",
    "def make_final_logs(text_df, sen_df, true_df, train_test_df, merged):\n",
    "    logging.info('I/O id summary')\n",
    "    logging.info('=======================================================================')\n",
    "    logging.info(pretty_str('all kw_match articles in raw data:', True))      # asserted by check_asserts()\n",
    "    logging.info(pretty_str('all matchedsentences in kw_match data:', True))\n",
    "    logging.info(pretty_str('unique articles:', len(text_df.id.unique())))\n",
    "    logging.info(pretty_str('unique articles w/ kw match:', len(sen_df.article_id.unique())))\n",
    "    logging.info(pretty_str('unique matched sentences:', len(sen_df.id.unique())))\n",
    "    logging.info(pretty_str('unique matched sentences relevant:', len(true_df.matchedsentence_id.unique())))\n",
    "    logging.info(pretty_str('unique matched officers relevant:', len(true_df.id.unique())))\n",
    "    logging.info(pretty_str('unique articles in train_test:', len(train_test_df.article_id.unique()), newline=True))\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO OUTPUT:\n",
    "# 1. article_id (given in data)\n",
    "# 2. article text (given in data)\n",
    "# 3. relevant (if article in true_df)\n",
    "# 4. test (if article is reserved for testing model)     Per TS: 500 train, 100 test for initial train\n",
    "# (may add cols like author or title)\n",
    "\n",
    "# CONSIDERING\n",
    "# correct_kw_match? does article_id conflict also occur with matchedsentence_id?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique relevant articles:                         316\n",
      "unique irrelevant articles:                       29616\n",
      "relevant and irrelevant disjoint:                 False\n",
      "size of overlap:                                  225\n",
      "amended relevant column:                          True\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('mode.chained_assignment', 'raise')\n",
    "# __main__\n",
    "\n",
    "# newsarticle: initial dataset\n",
    "#    - has all the data related to the article as it was pulled into feed\n",
    "# matchedsentence: initial keyword filter\n",
    "#    - has all the data related to every article with at least one sentence matching a keyword\n",
    "# matchedsentence_officers: manual filter (Rajiv)\n",
    "#    - has select columns linking identified officer badges and articles confirmed relevant by Rajiv\n",
    "# NOTE: If an article is not in the manual filter set, it is not relevant\n",
    "news_text = '../input/news_articles_newsarticle.csv.gz'\n",
    "news_included = '../input/news_articles_matchedsentence.csv.gz'\n",
    "news_true = '../input/news_articles_matchedsentence_officers.csv.gz'\n",
    "\n",
    "text_df = open_gz(news_text)\n",
    "sen_df = open_gz(news_included)\n",
    "true_df = open_gz(news_true)\n",
    "check_asserts(text_df, sen_df, true_df)\n",
    "\n",
    "less_text, less_sen, less_true = prep_dfs(text_df, sen_df, true_df)\n",
    "merged = merge_dfs(less_text, less_sen, less_true)\n",
    "\n",
    "# make sure every article_id has a corresponding 'relevant' value\n",
    "all_ids = set(merged.article_id.unique())\n",
    "relevant_articles = set(merged.loc[(merged.relevant == 1)].article_id.unique())\n",
    "irrelevant_articles = set(merged.loc[(merged.relevant == 0)].article_id.unique())\n",
    "rel_vals = relevant_articles.union(irrelevant_articles)\n",
    "assert all_ids.difference(rel_vals) == set()\n",
    "overlap = relevant_articles.intersection(irrelevant_articles)\n",
    "print(pretty_str('unique relevant articles:', len(relevant_articles)))\n",
    "print(pretty_str('unique irrelevant articles:', len(irrelevant_articles)))\n",
    "# check for conflicting 'relevant' values, correct if present\n",
    "print(pretty_str('relevant and irrelevant disjoint:', overlap == set()))\n",
    "if overlap != set():\n",
    "    print(pretty_str('size of overlap:', len(overlap)))\n",
    "    temp = merged\n",
    "    merged = correct_relevant(temp)\n",
    "    print(pretty_str('amended relevant column:', True))\n",
    "\n",
    "# proceed with generating training data\n",
    "merged = make_train_test_cols(merged, pos_rate=0.50)\n",
    "train_test_df = make_train_test_df(merged)\n",
    "\n",
    "# generate source_id, author, keyword, reports\n",
    "src_report = make_report(merged, 'source_id')\n",
    "author_report = make_report(merged, 'author')\n",
    "kw_report = make_report(merged, 'extracted_keywords')\n",
    "\n",
    "# save outputs\n",
    "train_test_df.to_parquet('../output/train-test.parquet')\n",
    "#news.to_parquet('../output/news.parquet')\n",
    "#src_report.to_parquet('../output/source_report.parquet')\n",
    "#author_report.to_parquet('../output/author_report.parquet')\n",
    "#kw_report.to_parquet('../output/keyword_report.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimated true pos_rate\n",
    "kw_match_n = merged.loc[merged.kw_match==1].article_id.count()\n",
    "relevant_n = merged.loc[merged.relevant==1].article_id.count()\n",
    "round(relevant_n/kw_match_n, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there any articles that contain a matched sentence but kw_match isn't True?\n",
    "match = set(merged.loc[merged.kw_match == 1].article_id.unique())\n",
    "no_match = set(merged.loc[merged.kw_match == 0].article_id.unique())\n",
    "match.intersection(no_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "(602, 4)\n",
      "597\n"
     ]
    }
   ],
   "source": [
    "# outgoing train_test asserts:\n",
    "#    1. No article_id or content is missing from either train or test sets\n",
    "#    2. No article_id or content appears in both train AND test sets\n",
    "#    3. Every article_id has a relevant, test value\n",
    "#    - Could assert pos_rate with margin of error +- 0.1\n",
    "\n",
    "# outgoing rule 1\n",
    "assert train_test_df.loc[train_test_df.article_id.isnull()].shape == (0,4)\n",
    "assert train_test_df.loc[train_test_df.content.isnull()].shape == (0,4)\n",
    "\n",
    "# outgoing rule 2\n",
    "train_articles = set(train_test_df.loc[train_test_df.test == 0].article_id.unique())\n",
    "test_articles = set(train_test_df.loc[train_test_df.test == 1].article_id.unique())\n",
    "assert train_articles.isdisjoint(test_articles)\n",
    "train_contents = set(train_test_df.loc[train_test_df.test == 0].content.unique())\n",
    "test_contents = set(train_test_df.loc[train_test_df.test == 1].content.unique())\n",
    "print(train_contents.isdisjoint(test_contents))\n",
    "\n",
    "# caveat to rule 2: duplicate \n",
    "article_ids = set(train_test_df.article_id.unique())\n",
    "contents = set(train_test_df.content.unique())\n",
    "print(train_test_df.shape)\n",
    "assert len(article_ids) == train_test_df.shape[0]\n",
    "print(len(contents))\n",
    "\n",
    "# outgoing rule 3\n",
    "assert train_test_df.loc[train_test_df.relevant.isnull()].shape == (0,4)\n",
    "assert train_test_df.loc[train_test_df.test.isnull()].shape == (0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicated content shape: (10, 4)\n",
      "article_ids in train_test_df implicated by dup_content: 10\n",
      "article_ids in merged implicated by dup_content: 10\n"
     ]
    }
   ],
   "source": [
    "# Rule 1 violation: Why is unique content < number of rows\n",
    "dup_content = train_test_df.loc[train_test_df.duplicated(subset='content')].content.values.tolist()\n",
    "if dup_content != []:\n",
    "    dup_content_df = train_test_df.loc[train_test_df.content.isin(dup_content)]\n",
    "    print('duplicated content shape:', dup_content_df.shape)\n",
    "    dup_content_ids = dup_content_df.article_id.unique().tolist()\n",
    "    print('article_ids in train_test_df implicated by dup_content:', len(dup_content_ids))\n",
    "    all_dup_content_ids = merged.loc[merged.article_id.isin(dup_content_ids)].article_id.unique().tolist()\n",
    "    print('article_ids in merged implicated by dup_content:', len(all_dup_content_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate text shape:\t\t\t (26765, 12)\n",
      "unique text samples duplicated:\t\t 580\n",
      "articles affected by duplicate text:\t 410\n"
     ]
    }
   ],
   "source": [
    "# Are matchedsentence_ids unique by text, or by text in unique article?\n",
    "dup_text = merged.loc[merged.duplicated(subset='text')].text.unique().tolist()\n",
    "dup_text_df = merged.loc[merged.text.isin(dup_text)]\n",
    "\n",
    "dup_text_ids = {}\n",
    "for tup in dup_text_df.itertuples():\n",
    "    this_art_id = tup.article_id\n",
    "    this_mat_id = tup.matchedsentence_id\n",
    "    if str(tup.text) != 'nan':\n",
    "        this_art_id = tup.article_id\n",
    "        this_mat_id = tup.matchedsentence_id\n",
    "        if tup.text not in dup_text_ids:\n",
    "            dup_text_ids[tup.text] = {'article_id': [this_art_id], 'matchedsentence_id': [this_mat_id]}\n",
    "        else:\n",
    "            if this_art_id not in dup_text_ids[tup.text]['article_id']:\n",
    "                dup_text_ids[tup.text]['article_id'].append(this_art_id)\n",
    "            if this_mat_id not in dup_text_ids[tup.text]['matchedsentence_id']:\n",
    "                dup_text_ids[tup.text]['matchedsentence_id'].append(this_mat_id)\n",
    "\n",
    "multiple_art = 0\n",
    "for text, id_dict in dup_text_ids.items():\n",
    "    if (len(id_dict['article_id']) > 1):\n",
    "        multiple_art += 1\n",
    "        # suspect sentences found in distinct articles are processed as distinct sentences\n",
    "        # matchedsentence_id only refers to uniqueness within article, not in database\n",
    "        assert len(id_dict['article_id']) == len(id_dict['matchedsentence_id'])\n",
    "\n",
    "print('duplicate text shape:\\t\\t\\t', dup_text_df.shape)\n",
    "print('unique text samples duplicated:\\t\\t', len(dup_text_ids))\n",
    "print('articles affected by duplicate text:\\t', text_mult_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Caddo Parish School announced Monday morning that Huntington High School will have an early release after power outage. Students will be released at 11 a.m. for pick up and bus release. Caddo Parish Schools said they are currently working with SWEPCO to restore power to the campus. SWEPCO estimates power will be restored later this afternoon. School will remain closed for the remainder of the day and will be in normal operation tomorrow. More:Shreveport Police Department officer terminated for violation of rules and regulations Makenzie Boucher is a reporter with the Shreveport Times. Contact her at mboucher@gannett.com.']\n"
     ]
    }
   ],
   "source": [
    "print(merged.loc[merged.extracted_keywords == \"{'terminated', 'officer', 'police'}\"].content.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>content</th>\n",
       "      <th>relevant</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25391</th>\n",
       "      <td>31316</td>\n",
       "      <td>A prosecutor is denying accusations that detec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25403</th>\n",
       "      <td>31266</td>\n",
       "      <td>(The Center Square) — Motorists on the Atchafa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25404</th>\n",
       "      <td>31264</td>\n",
       "      <td>Shreveport, La -- A Shreveport man who police ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25410</th>\n",
       "      <td>31255</td>\n",
       "      <td>A 25-year-old man has been identified as the p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25473</th>\n",
       "      <td>31151</td>\n",
       "      <td>\\nNEW ORLEANS (WGNO) — On Monday morning the U...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36030</th>\n",
       "      <td>460</td>\n",
       "      <td>Despite a slow down because of Hurricane Ida, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36040</th>\n",
       "      <td>413</td>\n",
       "      <td>The Innocence Project New Orleans has filed ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36045</th>\n",
       "      <td>405</td>\n",
       "      <td>A Louisiana State Police trooper who initiated...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36097</th>\n",
       "      <td>391</td>\n",
       "      <td>The number of COVID-19 cases among people inca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36105</th>\n",
       "      <td>373</td>\n",
       "      <td>At a press conference Wednesday, NOLA Public S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id                                            content  \\\n",
       "25391       31316  A prosecutor is denying accusations that detec...   \n",
       "25403       31266  (The Center Square) — Motorists on the Atchafa...   \n",
       "25404       31264  Shreveport, La -- A Shreveport man who police ...   \n",
       "25410       31255  A 25-year-old man has been identified as the p...   \n",
       "25473       31151  \\nNEW ORLEANS (WGNO) — On Monday morning the U...   \n",
       "...           ...                                                ...   \n",
       "36030         460  Despite a slow down because of Hurricane Ida, ...   \n",
       "36040         413  The Innocence Project New Orleans has filed ba...   \n",
       "36045         405  A Louisiana State Police trooper who initiated...   \n",
       "36097         391  The number of COVID-19 cases among people inca...   \n",
       "36105         373  At a press conference Wednesday, NOLA Public S...   \n",
       "\n",
       "       relevant  test  \n",
       "25391         1     0  \n",
       "25403         0     0  \n",
       "25404         0     0  \n",
       "25410         0     0  \n",
       "25473         0     0  \n",
       "...         ...   ...  \n",
       "36030         1     0  \n",
       "36040         0     0  \n",
       "36045         1     1  \n",
       "36097         0     0  \n",
       "36105         0     0  \n",
       "\n",
       "[598 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>matchedsentence_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>officer_id</th>\n",
       "      <th>extracted_keywords</th>\n",
       "      <th>kw_match</th>\n",
       "      <th>relevant</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Keisha Swafford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Living with diabetes is a lifetime challenge f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Charles Salzer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As the Live Oak softball team begins postseaso...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Community News Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Oaks Sports Medicine certified athletic ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Community News Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Great American Cleanup Love the Boot event...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Community News Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gordon McKernan Injury Attorneys has launched ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36105</th>\n",
       "      <td>373</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Marta Jewson</td>\n",
       "      <td>Chief Operations Officer Tiffany Delcour estim...</td>\n",
       "      <td>At a press conference Wednesday, NOLA Public S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'officer'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36106</th>\n",
       "      <td>366</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carly Berlin</td>\n",
       "      <td>At a Monday press conference with New Orlean...</td>\n",
       "      <td>UPDATE: After this story was published, FEMA e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'officer'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36107</th>\n",
       "      <td>365</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Marta Jewson</td>\n",
       "      <td>Before students return to any campus, NOLA P...</td>\n",
       "      <td>Outside Frederick Douglass High School Thursda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'officer'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36108</th>\n",
       "      <td>362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Marta Jewson</td>\n",
       "      <td>Damage report As of Tuesday, roughly half of t...</td>\n",
       "      <td>About 250,000 Louisiana students remain out of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'officer'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36109</th>\n",
       "      <td>356</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Michael Isaac Stein</td>\n",
       "      <td>She also said that grid power had been restore...</td>\n",
       "      <td>One week after Hurricane Ida made landfall in ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'police'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36110 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id  matchedsentence_id  source_id                 author  \\\n",
       "0           31383                 NaN          4        Keisha Swafford   \n",
       "1           31381                 NaN          2         Charles Salzer   \n",
       "2           31380                 NaN          2  Community News Report   \n",
       "3           31378                 NaN          2  Community News Report   \n",
       "4           31377                 NaN          2  Community News Report   \n",
       "...           ...                 ...        ...                    ...   \n",
       "36105         373                 9.0          1           Marta Jewson   \n",
       "36106         366                 3.0          1           Carly Berlin   \n",
       "36107         365                 2.0          1           Marta Jewson   \n",
       "36108         362                 1.0          1           Marta Jewson   \n",
       "36109         356                 6.0          1    Michael Isaac Stein   \n",
       "\n",
       "                                                    text  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "36105  Chief Operations Officer Tiffany Delcour estim...   \n",
       "36106    At a Monday press conference with New Orlean...   \n",
       "36107    Before students return to any campus, NOLA P...   \n",
       "36108  Damage report As of Tuesday, roughly half of t...   \n",
       "36109  She also said that grid power had been restore...   \n",
       "\n",
       "                                                 content  officer_id  \\\n",
       "0      Living with diabetes is a lifetime challenge f...         NaN   \n",
       "1      As the Live Oak softball team begins postseaso...         NaN   \n",
       "2      North Oaks Sports Medicine certified athletic ...         NaN   \n",
       "3      The Great American Cleanup Love the Boot event...         NaN   \n",
       "4      Gordon McKernan Injury Attorneys has launched ...         NaN   \n",
       "...                                                  ...         ...   \n",
       "36105  At a press conference Wednesday, NOLA Public S...         NaN   \n",
       "36106  UPDATE: After this story was published, FEMA e...         NaN   \n",
       "36107  Outside Frederick Douglass High School Thursda...         NaN   \n",
       "36108  About 250,000 Louisiana students remain out of...         NaN   \n",
       "36109  One week after Hurricane Ida made landfall in ...         NaN   \n",
       "\n",
       "      extracted_keywords  kw_match  relevant  train  test  \n",
       "0                    NaN         0         0      0     0  \n",
       "1                    NaN         0         0      0     0  \n",
       "2                    NaN         0         0      0     0  \n",
       "3                    NaN         0         0      0     0  \n",
       "4                    NaN         0         0      0     0  \n",
       "...                  ...       ...       ...    ...   ...  \n",
       "36105        {'officer'}         1         0      1     0  \n",
       "36106        {'officer'}         1         0      0     0  \n",
       "36107        {'officer'}         1         0      0     0  \n",
       "36108        {'officer'}         1         0      0     0  \n",
       "36109         {'police'}         1         0      0     0  \n",
       "\n",
       "[36110 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports\n",
    "- `extracted_keywords` in train/test/rem\n",
    "- sources in train/test/rem\n",
    "- authors in train/test/rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_keywords</th>\n",
       "      <th>kw_match</th>\n",
       "      <th>relevant_count</th>\n",
       "      <th>relevant_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'police', 'terminated'}</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'terminated', 'officer'}</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'nopd', 'police', 'officer'}</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'police', 'officer'}</td>\n",
       "      <td>889</td>\n",
       "      <td>191</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'nopd', 'officer'}</td>\n",
       "      <td>70</td>\n",
       "      <td>12</td>\n",
       "      <td>0.146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'terminated'}</td>\n",
       "      <td>91</td>\n",
       "      <td>14</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'officer'}</td>\n",
       "      <td>2764</td>\n",
       "      <td>422</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'police'}</td>\n",
       "      <td>6350</td>\n",
       "      <td>938</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'police', 'nopd', 'officer'}</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'nopd', 'police'}</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'nopd'}</td>\n",
       "      <td>503</td>\n",
       "      <td>43</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'police', 'terminated', 'officer'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'police', 'nopd'}</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     extracted_keywords  kw_match  relevant_count  \\\n",
       "6              {'police', 'terminated'}         4               4   \n",
       "0             {'terminated', 'officer'}         4               3   \n",
       "11        {'nopd', 'police', 'officer'}         5               2   \n",
       "5                 {'police', 'officer'}       889             191   \n",
       "8                   {'nopd', 'officer'}        70              12   \n",
       "9                        {'terminated'}        91              14   \n",
       "2                           {'officer'}      2764             422   \n",
       "4                            {'police'}      6350             938   \n",
       "10        {'police', 'nopd', 'officer'}         7               1   \n",
       "7                    {'nopd', 'police'}        20               2   \n",
       "12                             {'nopd'}       503              43   \n",
       "1   {'police', 'terminated', 'officer'}         1               0   \n",
       "3                    {'police', 'nopd'}        18               0   \n",
       "\n",
       "    relevant_perc  \n",
       "6           0.500  \n",
       "0           0.429  \n",
       "11          0.286  \n",
       "5           0.177  \n",
       "8           0.146  \n",
       "9           0.133  \n",
       "2           0.132  \n",
       "4           0.129  \n",
       "10          0.125  \n",
       "7           0.091  \n",
       "12          0.079  \n",
       "1           0.000  \n",
       "3           0.000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_report.sort_values(by='relevant_perc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     extracted_keywords  relevant_perc\n",
      "6              {'police', 'terminated'}          0.500\n",
      "0             {'terminated', 'officer'}          0.429\n",
      "11        {'nopd', 'police', 'officer'}          0.286\n",
      "5                 {'police', 'officer'}          0.177\n",
      "8                   {'nopd', 'officer'}          0.146\n",
      "9                        {'terminated'}          0.133\n",
      "2                           {'officer'}          0.132\n",
      "4                            {'police'}          0.129\n",
      "10        {'police', 'nopd', 'officer'}          0.125\n",
      "7                    {'nopd', 'police'}          0.091\n",
      "12                             {'nopd'}          0.079\n",
      "1   {'police', 'terminated', 'officer'}          0.000\n",
      "3                    {'police', 'nopd'}          0.000\n"
     ]
    }
   ],
   "source": [
    "print(kw_report[['extracted_keywords', 'relevant_perc']].sort_values(by='relevant_perc', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>kw_match</th>\n",
       "      <th>relevant_count</th>\n",
       "      <th>relevant_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3345</td>\n",
       "      <td>790</td>\n",
       "      <td>0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1497</td>\n",
       "      <td>144</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>831</td>\n",
       "      <td>107</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>75</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>154</td>\n",
       "      <td>68</td>\n",
       "      <td>0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>102</td>\n",
       "      <td>67</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>1204</td>\n",
       "      <td>53</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>528</td>\n",
       "      <td>43</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>303</td>\n",
       "      <td>42</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>304</td>\n",
       "      <td>32</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>381</td>\n",
       "      <td>31</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>25</td>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>22</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33</td>\n",
       "      <td>93</td>\n",
       "      <td>20</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>219</td>\n",
       "      <td>18</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>103</td>\n",
       "      <td>18</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>270</td>\n",
       "      <td>17</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31</td>\n",
       "      <td>214</td>\n",
       "      <td>16</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>0.277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>7</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>0.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>34</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source_id  kw_match  relevant_count  relevant_perc\n",
       "1           2      3345             790          0.191\n",
       "18         19      1497             144          0.088\n",
       "15         16       831             107          0.114\n",
       "0           1       255              75          0.227\n",
       "16         17       154              68          0.306\n",
       "23         25       102              67          0.396\n",
       "28         30      1204              53          0.042\n",
       "6           7       528              43          0.075\n",
       "30         32       303              42          0.122\n",
       "13         14       304              32          0.095\n",
       "11         12       381              31          0.075\n",
       "2           3       109              25          0.187\n",
       "3           4       170              22          0.115\n",
       "31         33        93              20          0.177\n",
       "12         13       219              18          0.076\n",
       "20         22       103              18          0.149\n",
       "7           8       270              17          0.059\n",
       "29         31       214              16          0.070\n",
       "25         27        34              13          0.277\n",
       "9          10        96               7          0.068\n",
       "10         11        23               6          0.207\n",
       "27         29        17               4          0.190\n",
       "14         15       130               4          0.030\n",
       "17         18        32               3          0.086\n",
       "32         34        52               3          0.055\n",
       "19         20       163               2          0.012\n",
       "8           9        36               2          0.053\n",
       "26         28         1               0          0.000\n",
       "24         26        17               0          0.000\n",
       "22         24         8               0          0.000\n",
       "21         23        16               0          0.000\n",
       "4           5         4               0          0.000\n",
       "5           6        15               0          0.000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_report.sort_values(by='relevant_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>kw_match</th>\n",
       "      <th>relevant_count</th>\n",
       "      <th>relevant_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Katie Gagliano</td>\n",
       "      <td>226</td>\n",
       "      <td>103</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Claire Taylor</td>\n",
       "      <td>152</td>\n",
       "      <td>100</td>\n",
       "      <td>0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>James Finn</td>\n",
       "      <td>237</td>\n",
       "      <td>81</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Staff Report</td>\n",
       "      <td>437</td>\n",
       "      <td>68</td>\n",
       "      <td>0.135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Joe Gyan Jr.</td>\n",
       "      <td>167</td>\n",
       "      <td>59</td>\n",
       "      <td>0.261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Ron Faucheux</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Bess Casserleigh</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>WBRZ News</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Special to The Town Talk</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>Emily Leiker</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       author  kw_match  relevant_count  relevant_perc\n",
       "266            Katie Gagliano       226             103          0.313\n",
       "4               Claire Taylor       152             100          0.397\n",
       "522                James Finn       237              81          0.255\n",
       "235              Staff Report       437              68          0.135\n",
       "179              Joe Gyan Jr.       167              59          0.261\n",
       "..                        ...       ...             ...            ...\n",
       "239              Ron Faucheux         2               0          0.000\n",
       "238         Bess Casserleigh          2               0          0.000\n",
       "237                 WBRZ News         4               0          0.000\n",
       "234  Special to The Town Talk         2               0          0.000\n",
       "647              Emily Leiker         1               0          0.000\n",
       "\n",
       "[648 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_report.sort_values(by='relevant_count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing input data\n",
    "\n",
    "### `text_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full text shape:                                  (29707, 12)\n",
      "full text cols:\n",
      " ['created_at', 'link', 'guid', 'source_id', 'updated_at', 'content', 'published_date', 'id', 'title', 'is_processed', 'author', 'url']\n"
     ]
    }
   ],
   "source": [
    "pretty_print('full text shape:', text_df.shape)\n",
    "print('full text cols:\\n', list(text_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29707 entries, 0 to 29706\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   created_at      29707 non-null  object\n",
      " 1   link            29707 non-null  object\n",
      " 2   guid            29707 non-null  object\n",
      " 3   source_id       29707 non-null  int64 \n",
      " 4   updated_at      29707 non-null  object\n",
      " 5   content         29254 non-null  object\n",
      " 6   published_date  29707 non-null  object\n",
      " 7   id              29707 non-null  int64 \n",
      " 8   title           29707 non-null  object\n",
      " 9   is_processed    29707 non-null  bool  \n",
      " 10  author          27270 non-null  object\n",
      " 11  url             29707 non-null  object\n",
      "dtypes: bool(1), int64(2), object(9)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "text_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             distinct value count by col\n",
      "=======================================================\n",
      "created_at                                        29707\n",
      "link                                              29707\n",
      "guid                                              29698\n",
      "source_id                                         34\n",
      "updated_at                                        29707\n",
      "content                                           28581\n",
      "published_date                                    529\n",
      "id                                                29707\n",
      "title                                             28392\n",
      "is_processed                                      1\n",
      "author                                            2200\n",
      "url                                               29707\n"
     ]
    }
   ],
   "source": [
    "get_unique_report(text_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sen_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched sen shape:                                (10470, 7)\n",
      "matched sen cols:\n",
      " ['id', 'created_at', 'updated_at', 'article_id', 'extracted_keywords', 'text', 'title']\n"
     ]
    }
   ],
   "source": [
    "pretty_print('matched sen shape:', sen_df.shape)\n",
    "print('matched sen cols:\\n', list(sen_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10470 entries, 0 to 10469\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  10470 non-null  int64 \n",
      " 1   created_at          10470 non-null  object\n",
      " 2   updated_at          10470 non-null  object\n",
      " 3   article_id          10470 non-null  int64 \n",
      " 4   extracted_keywords  10470 non-null  object\n",
      " 5   text                10470 non-null  object\n",
      " 6   title               10470 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 572.7+ KB\n"
     ]
    }
   ],
   "source": [
    "sen_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             distinct value count by col\n",
      "=======================================================\n",
      "id                                                10470\n",
      "created_at                                        10470\n",
      "updated_at                                        10470\n",
      "article_id                                        4323\n",
      "extracted_keywords                                60\n",
      "text                                              9925\n",
      "title                                             4179\n"
     ]
    }
   ],
   "source": [
    "get_unique_report(sen_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `true_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched true shape:                               (735, 3)\n",
      "matched true cols:\n",
      " ['id', 'matchedsentence_id', 'officer_id']\n"
     ]
    }
   ],
   "source": [
    "pretty_print('matched true shape:', true_df.shape)\n",
    "print('matched true cols:\\n', list(true_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 735 entries, 0 to 734\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   id                  735 non-null    int64\n",
      " 1   matchedsentence_id  735 non-null    int64\n",
      " 2   officer_id          735 non-null    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 17.4 KB\n"
     ]
    }
   ],
   "source": [
    "true_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             distinct value count by col\n",
      "=======================================================\n",
      "id                                                355\n",
      "matchedsentence_id                                479\n",
      "officer_id                                        355\n"
     ]
    }
   ],
   "source": [
    "get_unique_report(true_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
